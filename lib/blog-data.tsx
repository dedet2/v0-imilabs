export interface BlogPost {
  id: number
  title: string
  description: string
  category: string
  date: string
  readTime: string
  image: string
  slug: string
  author: string
  content: string[]
}

// Combined blog posts - Original 7 articles first (newest to oldest), then 18 Squarespace imports
export const blogPosts: BlogPost[] = [
  // ============================================
  // ORIGINAL 7 ARTICLES (January 2026 - November 2025)
  // ============================================
  {
    id: 1,
    title: "The EU AI Act: What Leaders Need to Know in 2026",
    description: "A comprehensive guide to the EU AI Act requirements and how organizations can prepare for compliance.",
    category: "AI Governance",
    date: "January 15, 2026",
    readTime: "8 min read",
    image: "/modern-corporate-office-with-diverse-team-working-on-ai-governance.jpg",
    slug: "eu-ai-act-guide-2026",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The EU AI Act represents the most comprehensive AI regulation globally, and 2026 marks a critical year for compliance. Organizations deploying AI systems in the European Union must understand their obligations and take proactive steps to ensure compliance. This landmark legislation will fundamentally reshape how businesses develop, deploy, and maintain artificial intelligence systems across all sectors.",
      "As someone who has spent over two decades at the intersection of technology and policy, I've watched this regulation evolve from early proposals to the comprehensive framework we see today. The Act didn't emerge in a vacuum—it's the culmination of years of growing concern about AI's impact on fundamental rights, safety, and democratic values.",
      "Understanding the Risk-Based Approach: The Act categorizes AI systems into four distinct risk levels, each with different compliance obligations. Unacceptable risk systems are outright banned—these include social scoring systems, real-time biometric identification in public spaces (with limited exceptions), and AI that manipulates human behavior to circumvent free will. High-risk systems face the most stringent requirements and include AI used in critical infrastructure, education, employment, essential services, law enforcement, and border management.",
      "Limited risk systems, such as chatbots and deepfakes, must meet transparency requirements—users must be informed they're interacting with AI. Minimal risk systems, which constitute the vast majority of AI applications, face no specific regulatory requirements under the Act, though general principles of responsible AI development still apply.",
      "Key Compliance Requirements for High-Risk Systems: Organizations deploying high-risk AI must implement comprehensive risk management systems that identify, analyze, evaluate, and mitigate risks throughout the AI lifecycle. This isn't a one-time assessment—it requires ongoing monitoring and updates as the system evolves and new risks emerge.",
      "Data governance requirements mandate that training, validation, and testing datasets meet specific quality criteria. Organizations must examine data for potential biases, ensure data is relevant and representative, and implement appropriate data governance measures. This is particularly challenging for organizations using third-party datasets or foundation models.",
      "Technical documentation requirements are extensive. Organizations must maintain detailed records of the AI system's design, development, and deployment. This includes information about training data, design choices, testing procedures, and performance metrics. The documentation must be sufficient for regulators to assess compliance.",
      "Human oversight requirements ensure that humans can effectively supervise high-risk AI systems. This means building in appropriate human-machine interfaces, ensuring operators understand the system's capabilities and limitations, and creating mechanisms for human intervention when necessary.",
      "Transparency requirements extend to users, who must be informed when they're interacting with or subject to decisions made by AI systems. This includes providing clear information about the system's capabilities, limitations, and the role of AI in decision-making.",
      "The organizations that thrive under the EU AI Act will be those that view compliance not as a burden but as an opportunity to build trust, differentiate from competitors, and create AI systems that genuinely serve human flourishing. The regulatory landscape is shifting—the question is whether your organization will lead or follow.",
    ],
  },
  {
    id: 2,
    title: "Disability as Innovation Driver: The Business Case",
    description: "How inclusive design and accessibility-first thinking can unlock new markets and drive competitive advantage.",
    category: "Tech Equity",
    date: "January 8, 2026",
    readTime: "6 min read",
    image: "/diverse-team-collaborating-on-inclusive-technology.jpg",
    slug: "disability-innovation-driver",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "When we design for the margins, we create solutions that benefit everyone. This isn't just a moral imperative—it's a business strategy that has proven to unlock significant value for organizations willing to embrace inclusive design. Throughout my career, I've seen firsthand how accessibility-first thinking transforms not just products, but entire organizational cultures.",
      "The numbers tell a compelling story. According to the World Health Organization, 1.3 billion people globally live with some form of disability—that's 16% of the world's population. This community represents $13 trillion in annual disposable income. Add aging populations (by 2050, one in six people will be over 65), temporary disabilities, and situational impairments, and the addressable market for accessible products expands dramatically.",
      "The Curb Cut Effect: Innovation That Benefits Everyone: The curb cut effect, named after the sloped sidewalk cuts originally designed for wheelchair users, illustrates how solutions designed for specific populations often benefit everyone. Parents with strollers, travelers with luggage, delivery workers with hand trucks—all benefit from curb cuts. The same principle applies throughout technology.",
      "Voice assistants, originally developed to help people with motor impairments, are now used by hundreds of millions of people. Closed captions, created for deaf and hard-of-hearing viewers, are used by 80% of people who enable them for reasons other than hearing loss—in noisy environments, while learning languages, or to improve comprehension.",
      "The keyboard shortcuts that power productivity for millions were originally accessibility features. Autocomplete and predictive text emerged from assistive technology research. Time and again, innovations designed for disability have become mainstream features that generate billions in value.",
      "More fundamentally, accessibility-first design creates better products for everyone. The discipline of designing for extreme users forces clearer thinking, simpler interfaces, and more robust systems. It's a competitive advantage hiding in plain sight—one that most of your competitors are still ignoring.",
    ],
  },
  {
    id: 3,
    title: "Building Ethical AI Systems: A Framework for Success",
    description: "Practical steps for implementing ethical AI governance that protects your organization and serves all users.",
    category: "AI Governance",
    date: "December 20, 2025",
    readTime: "10 min read",
    image: "/executive-team-reviewing-compliance-dashboard.jpg",
    slug: "ethical-ai-framework",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Ethical AI isn't just about avoiding harm—it's about building systems that actively promote fairness, transparency, and human flourishing. This requires a comprehensive framework that addresses every stage of the AI lifecycle, from initial conception through deployment, monitoring, and eventual decommissioning.",
      "Over my years advising Fortune 500 companies on AI governance, I've developed a framework built on four pillars that has proven effective across industries and use cases. These pillars—Lead with Curiosity, Be Accountable, Solve for One, Extend to Many, and Take Action—provide both philosophical grounding and practical guidance.",
      "Pillar 1: Lead with Curiosity - The first pillar challenges us to examine our assumptions and actively seek out blind spots. AI systems are built by humans, trained on human-generated data, and reflect human decisions at every turn. Without intentional curiosity, we inevitably encode our biases and limitations into these systems.",
      "Pillar 2: Be Accountable - Accountability in AI means creating clear lines of responsibility for AI decisions. When an AI system causes harm, who is responsible? The developer? The deploying organization? The operator? Ethical AI governance requires answering these questions before systems are deployed.",
      "Pillar 3: Solve for One, Extend to Many - This pillar, borrowed from inclusive design principles, reminds us to design for specific users with specific needs—particularly those most likely to be harmed by AI systems. By solving for the most vulnerable, we often create solutions that work better for everyone.",
      "Pillar 4: Take Action - Knowledge without action is insufficient. Ethical AI requires ongoing commitment to monitoring, auditing, and improving systems. It requires creating feedback mechanisms that surface problems early and empower those affected to seek redress.",
      "The organizations that master ethical AI development will build trust with customers, attract top talent, navigate regulatory requirements more easily, and create AI systems that genuinely serve human flourishing. The framework is clear—now it's time to put it into practice.",
    ],
  },
  {
    id: 4,
    title: "The ROI of Accessible Technology",
    description: "Quantifying the business value of accessibility investments and inclusive design practices.",
    category: "Business Impact",
    date: "December 12, 2025",
    readTime: "7 min read",
    image: "/diverse-team-celebrating-inclusive-product-launch.jpg",
    slug: "roi-accessible-technology",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Accessibility investments deliver measurable returns across multiple dimensions: risk mitigation, market expansion, operational efficiency, brand value, and talent attraction. Understanding and quantifying these returns is essential for building the business case for inclusive design and securing the resources needed for meaningful accessibility improvements.",
      "For too long, accessibility has been framed primarily as a compliance obligation or charitable gesture. While legal compliance and moral considerations are important, they rarely drive sustained organizational commitment. By quantifying the business value of accessibility, we can shift the conversation from 'should we invest in accessibility?' to 'how much should we invest to maximize returns?'",
      "Risk Mitigation: The Cost of Inaction - The legal landscape around accessibility has transformed dramatically. ADA-related lawsuits increased 320% between 2018 and 2025, with digital accessibility claims now comprising the majority of cases. Settlement costs regularly reach six figures, and defending accessibility lawsuits typically costs $50,000-$100,000 regardless of outcome.",
      "Market Expansion: The Disability Market Advantage - The disability market represents $13 trillion in annual disposable income globally. In the US alone, people with disabilities control over $490 billion in disposable income. Add friends and family who factor accessibility into purchasing decisions, and the market influence expands to over $1 trillion.",
      "Operational Efficiency: Accessibility as Quality - Accessible systems tend to be better-engineered systems. The discipline of meeting accessibility standards often reveals and forces correction of underlying code quality issues. Accessible content is more easily parsed by search engines, improving SEO performance.",
      "Brand Value and Reputation - In an era of stakeholder capitalism and conscious consumerism, accessibility increasingly influences brand perception. Companies known for accessibility leadership enjoy enhanced reputation among consumers, employees, and investors who prioritize social responsibility.",
    ],
  },
  {
    id: 5,
    title: "Algorithmic Bias: Detection and Prevention Strategies",
    description: "Understanding how bias enters AI systems and practical approaches to identify and mitigate it.",
    category: "AI Governance",
    date: "December 5, 2025",
    readTime: "9 min read",
    image: "/diverse-tech-team-collaborating-in-modern-office.jpg",
    slug: "algorithmic-bias-prevention",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Algorithmic bias represents one of the most significant challenges facing AI development today. When machine learning systems encode and amplify existing societal biases, the consequences can be severe—from discriminatory hiring decisions to biased criminal sentencing recommendations to healthcare disparities that cost lives.",
      "Understanding how bias enters AI systems is the first step toward addressing it. Bias can creep in at every stage of the AI development lifecycle: during problem formulation, data collection, feature selection, model training, evaluation, and deployment. Each stage presents unique risks and requires specific mitigation strategies.",
      "Sources of Bias in AI Systems - Historical bias in training data is perhaps the most recognized source of algorithmic bias. When AI systems learn from data that reflects historical discrimination, they learn to perpetuate that discrimination. A hiring algorithm trained on past hiring decisions will learn any bias present in those decisions.",
      "Representation bias occurs when training data doesn't adequately represent all populations the system will serve. Facial recognition systems trained primarily on light-skinned faces perform poorly on darker-skinned faces—not because the technology is inherently biased, but because the training data was unrepresentative.",
      "Measurement bias arises when the features used as proxies for desired outcomes don't mean the same thing across different populations. Using zip code as a feature, for example, can encode racial and economic segregation patterns into algorithmic decisions.",
      "Detection and Mitigation Strategies - Detecting bias requires defining what fairness means in your specific context—a surprisingly difficult task. Different fairness metrics often conflict with each other, making trade-offs inevitable. Organizations must engage stakeholders in defining acceptable fairness criteria.",
      "The goal isn't to create perfectly unbiased systems—that's likely impossible. The goal is to build systems with understood limitations, appropriate safeguards, and meaningful human oversight. This requires ongoing vigilance, regular auditing, and a commitment to continuous improvement.",
    ],
  },
  {
    id: 6,
    title: "Rest as Resistance: The Wellness Imperative for Leaders",
    description: "Why executive wellness and intentional rest are essential for sustainable leadership and innovation.",
    category: "Wellness",
    date: "November 28, 2025",
    readTime: "5 min read",
    image: "/diverse-executives-in-meditation-session.jpg",
    slug: "rest-as-resistance-leaders",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "In a culture that glorifies hustle and equates busyness with importance, rest becomes a radical act. For leaders—especially those from marginalized communities who face additional pressures to prove their worth—intentional rest is not just self-care; it's a form of resistance against systems designed to extract maximum productivity at the expense of human flourishing.",
      "The research is clear: chronic stress and sleep deprivation impair cognitive function, emotional regulation, and decision-making. Leaders operating under these conditions make poorer decisions, treat their teams worse, and are more likely to burn out. Yet our culture continues to celebrate leaders who sacrifice sleep, skip vacations, and wear their exhaustion as a badge of honor.",
      "The Historical Context of Rest as Resistance - The concept of rest as resistance has deep roots in Black feminist thought. Tricia Hersey, founder of The Nap Ministry, traces this idea to the brutal history of slavery, where Black bodies were treated as machines for productivity. Claiming rest—asserting that our bodies are not meant simply for labor—is an act of reclaiming our humanity.",
      "For BIPOC leaders and those from other marginalized groups, the pressure to perform is amplified. We often feel we must work twice as hard to receive half the recognition. We navigate microaggressions, code-switching, and the weight of being 'the only one' in many rooms. This additional cognitive and emotional labor makes rest even more essential—and often even harder to take.",
      "Practical Strategies for Intentional Rest - Rest as resistance means reclaiming your time and energy from systems that would consume them entirely. It means recognizing that your value is not determined by your productivity. It means modeling sustainable leadership for your teams and refusing to perpetuate cultures of overwork.",
      "Start by examining your relationship with rest. Notice when guilt arises around taking breaks. Question the narratives that equate constant work with virtue. Then, begin to build rest into your routines—not as a reward for productivity, but as a fundamental human need and a strategic investment in your long-term effectiveness.",
    ],
  },
  {
    id: 7,
    title: "Navigating AI Governance: A C-Suite Perspective",
    description: "Strategic insights for executive leaders on building responsible AI governance frameworks.",
    category: "AI Governance",
    date: "November 20, 2025",
    readTime: "8 min read",
    image: "/professional-business-meeting-discussing-ai-govern.jpg",
    slug: "ai-governance-c-suite-perspective",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "AI governance has moved from a technical concern to a boardroom priority. As AI systems become increasingly central to business operations and customer experiences, executive leaders must develop the strategic competency to oversee AI responsibly. This requires understanding both the opportunities and the risks that AI presents.",
      "The business case for AI governance is compelling. Organizations with mature AI governance frameworks experience fewer regulatory penalties, stronger customer trust, reduced legal exposure, and better AI performance. They're also better positioned to attract AI talent, who increasingly want to work for organizations committed to responsible AI development.",
      "Building Governance Competency at the Executive Level - Effective AI governance starts with board-level understanding of AI capabilities and limitations. This doesn't mean every executive needs to become a data scientist—but they do need enough AI literacy to ask the right questions and evaluate the answers.",
      "Key Questions Every Executive Should Ask - What decisions are being made or influenced by AI systems? What data is being used to train and operate these systems? How are we testing for bias and ensuring fairness? What happens when the AI makes mistakes? How are we maintaining human oversight?",
      "Governance Structures That Work - Successful AI governance requires clear accountability structures. This typically includes an AI ethics committee or board, clear ownership of AI risk within existing risk management frameworks, defined escalation paths for ethical concerns, and regular reporting to the board on AI performance and incidents.",
      "The organizations that will thrive in an AI-driven future are those that treat governance not as a constraint but as a competitive advantage. By building robust governance frameworks now, you position your organization for sustainable AI success.",
    ],
  },

  // ============================================
  // 18 SQUARESPACE BLOG IMPORTS (April 2024 - March 2024)
  // Ordered from newest to oldest
  // ============================================
  {
    id: 8,
    title: "Ethical AI and Smart Lock Systems",
    description: "Examining the ethical implications of smart lock systems that use facial recognition technology and their impact on marginalized communities.",
    category: "AI Governance",
    date: "April 19, 2024",
    readTime: "7 min read",
    image: "/blog/amol-tyagi-0juktkotkpu-unsplash-1638x2048-2.jpg",
    slug: "ethical-ai-and-smart-lock-systems",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "I recently sat down with a group to discuss the pros and cons of emerging technologies from my perspective as both anthropologist and ethical technologist; specifically, smart lock systems. For those who may be unfamiliar with smart lock systems, they are a relatively new technological advancement that uses image and facial recognition software to enable users entry to businesses and residences thereby eliminating physical keys; this technology is believed to increase safety and ease of accessibility.",
      "No more misplaced and lost keys, costly locksmith services, and the ease of allowing temporary and/or limited access to vendors, guests, and service providers. These are the pros and admittedly, they are cost-efficient, time-saving, and an added convenience for some – perhaps, many.",
      "There is a misconception that AI is godlike, infallible even; but AI is a product of wholly fallible human design. Coded into the complex algorithms are the same biases we deal with in our day to day human experiences. Laypersons are more apt to buy into a science they don't fully understand and this leaves an already over-policed, vulnerable faction of the population at a heightened risk of unprecedented, unmitigated harm.",
      "Within the past month, a Black sixteen year old was seriously wounded after being shot by a White homeowner for ringing his doorbell in error. It is not only reasonable to suspect, but to assert the homeowner reacted with such heightened hostility towards the error and minor inconvenience due to his own preconceived notions about race.",
      "What, then, do we do when there is a discrepancy between the human-coded smartlock technology algorithms and the humans seeking safe, equitable access? The answer is complex, but begins with intentional, inclusive design that centers the most marginalized users from the very beginning of the development process.",
      "We must ask ourselves: Who is designing these systems? Are they representative of the communities who will be most impacted by their failures? Are there adequate testing protocols that account for the full spectrum of human diversity? And perhaps most importantly, what accountability measures exist when these systems inevitably fail?",
      "The convenience of emerging technologies should never come at the cost of safety for marginalized communities. As we continue to integrate AI into the most intimate spaces of our lives—our homes—we must demand that these systems are built with equity at their core, not as an afterthought.",
    ],
  },
  {
    id: 9,
    title: "The Pitfalls of Adversarial Clothing",
    description: "An exploration of adversarial clothing designed to confuse facial recognition systems and the unintended consequences for marginalized communities.",
    category: "Tech Equity",
    date: "April 18, 2024",
    readTime: "8 min read",
    image: "/blog/adversarial-clothing.png",
    slug: "pitfalls-of-adversarial-clothing",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "When I present on panels about equitable and inclusive design, there are two areas I emphasize; as both a social scientist and tech ethicist, these are the areas where we, as humans have the greatest opportunity to bring about transformative change.",
      "The first and most fundamental tool we have within our arsenal is the call-in. The call-in is the seed from which the best accessible, equitable, and inclusive products and processes take shape. Who am I designing this for? Who am I designing it with? If they are not one and the same, we must go back and begin again.",
      "The second is more of a guiding principle, 'Design for one, extend to many.' This principle from my friend and mentor, Kat Holmes is another essential tool in designing accessibly and equitably. When we design for the most marginalized, we create solutions that benefit everyone.",
      "I've written about hyper-reliance on facial recognition technology and the added layer of harm it causes for the oft-misidentified BIPOC and LGBTQ+ communities, so when adversarial clothing brands started to emerge, my interests were piqued and as it turns out, I wasn't alone.",
      "I recently sat with a small group to discuss the rapid growth of facial recognition technologies and more specifically the harms inevitably levied upon us by the designers, the consumers, and even so-called adversaries of these technologies. With a focus on accessibility, equity, and harm mitigation what remains clear is that the solution must center those most impacted.",
      "Adversarial clothing—garments designed with patterns that confuse facial recognition algorithms—seems like a clever solution to surveillance overreach. But we must ask: who can afford these specialized garments? Who has the privilege of wearing unusual patterns without drawing additional scrutiny? For BIPOC communities already subject to heightened surveillance, wearing 'anti-surveillance' clothing may actually increase their visibility to human observers and law enforcement.",
      "The real solution to harmful surveillance technology isn't better camouflage for individuals—it's systemic change that addresses the deployment of these technologies in the first place. We need robust regulation, community oversight, and accountability for the organizations that deploy facial recognition systems.",
      "Rather than asking marginalized communities to adapt to harmful technology, we should be demanding that technology adapt to serve all communities equitably. The burden of protection should not fall on those most vulnerable to harm.",
    ],
  },
  {
    id: 10,
    title: "Facial Recognition and Racial Bias",
    description: "Examining how facial recognition technology disproportionately harms BIPOC communities and the urgent need for regulation.",
    category: "AI Governance",
    date: "April 18, 2024",
    readTime: "9 min read",
    image: "/blog/ariel-sion-i7v-btpnktg-unsplash-2048x1365-2.jpg",
    slug: "facial-recognition-and-racial-bias",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "It is estimated that almost half of American adults – over 117 million people, as of 2016 – have photos within a facial recognition network used by law enforcement. This participation occurs without consent, or even awareness, and is bolstered by a lack of legislative oversight. More disturbingly, however, the current implementation of these technologies involves significant racial bias, particularly against Black Americans.",
      "In as many years, 3 Black men have had their lives upended by wrongful arrests. Robert Williams, Michael Oliver, and Nijeer Parks were misidentified by facial recognition software, arrested, and held under suspicion of crimes ranging from petty theft to assault of a police officer. For Parks, who was accused of the more serious crimes of assault and eluding the police, the fight to clear his name went on for the better part of a year.",
      "Before his case was thrown out of court, and his name cleared, Parks would go on to spend 10 days in jail, all due to hyper-reliance on technology. In the later filed lawsuit against the Woodbridge Police Department, its affiliates and Idemia the company behind the facial recognition software, Parks alleged that proper investigative techniques were forgone in lieu of faulty technology.",
      "Despite widely published research findings detailing the issues of misidentification of darker skinned faces by facial recognition technologies, law enforcement's hyper-reliance remains. For BIPOC, and most notably, dark-skinned Black women (for whom misidentification occurs as often as 33% of the time compared to that of white men) this adds an added layer of concern.",
      "'Automated systems are not inherently neutral. They reflect the priorities, preferences, and prejudices—the coded gaze—of those who have the power to mold artificial intelligence.' - Gendershades.org",
      "BIPOC are more highly surveilled by law enforcement agencies, more likely to be arrested, more likely to receive harsher sentences when convicted, and most likely to be the victims of wrongful convictions. Facial recognition technology, in its current state, amplifies all of these existing inequities.",
      "The solution is not better facial recognition technology—it is robust regulation that limits how and when these systems can be used, mandatory bias testing before deployment, and meaningful accountability when these systems cause harm. Until we have these safeguards in place, the continued deployment of facial recognition technology represents an ongoing civil rights violation against BIPOC communities.",
    ],
  },
  {
    id: 11,
    title: "Digital Blackface: Are you complicit?",
    description: "Understanding digital blackface in online communication and its harmful impact on Black communities.",
    category: "Tech Equity",
    date: "April 7, 2024",
    readTime: "8 min read",
    image: "/blog/priscilla-du-preez-bjhuu6bpuza-unsplash-2048x1365-2.jpg",
    slug: "digital-blackface-are-you-complicit",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "'Digital blackface' is used to describe various types of minstrel performance that become available in cyberspace. Blackface minstrelsy is a theatrical tradition dating back to the early 19th century, in which performers 'blacken' themselves up with costume and behaviors to act as black caricatures. The performances put society's most racist sensibilities on display and in turn fed them back to audiences to intensify these feelings and disperse them across culture. - Lauren Michele Jackson, Teen Vogue",
      "For those of us at the forefront of the fight for liberation, the obstacles seem endless. It would appear that every facet of our daily existence and interactions are marred by pervasive influence of white supremacy–or rather, 'white supremacist delusion' as Sonya Renee Taylor has coined it. We have long since uncovered the truth about the social construct of race, but knowing better and living in that truth don't always align.",
      "Based on data compiled by Statista, it is estimated that in 2021 the average American spent 8+ hours on digital media daily, communicating with people from all walks of life, and from all over the world. A third of your day, everyday, is either an opportunity for harm or harm reduction and liberation.",
      "We've all seen it so much that in many ways, we are desensitized, while some others become hyperaware and/or hypervigilant. There's a Facebook or Twitter thread or maybe even group chat amongst peers and someone drops a GIF or a meme and the group is divided. Perhaps, it's RHOA (Real Housewives of Atlanta) reality star Nene Leakes, or a lesser known, likely unsuspecting, usually Black or Brown person whose image has been co-opted and turned into a meme via a meme-making app or some other photo-editing/captioning software.",
      "As harmless and even humorous as this seems, these are real people and we must ask ourselves, 'Why them?' Why not snap a selfie to express your emotions, or take a little extra time to search for an image closer to your own likeness? The answer often reveals uncomfortable truths about how Black expression is consumed as entertainment while Black people themselves are marginalized.",
      "Digital blackface allows non-Black people to adopt Black personas, Black expressions, and Black culture for entertainment or emphasis while maintaining distance from the actual experiences and struggles of Black people. It's a way of consuming Blackness without accountability, of performing proximity to Black culture while perpetuating the systems that harm Black communities.",
      "The next time you reach for that GIF or meme, pause and ask yourself: Am I amplifying Black voices, or am I appropriating Black expression? Am I engaging with Black culture respectfully, or am I participating in a digital form of minstrelsy? The answer matters.",
    ],
  },
  {
    id: 12,
    title: "What is Liberatory Design?",
    description: "An introduction to liberatory design principles and how they can transform how we build products and systems.",
    category: "Tech Equity",
    date: "April 6, 2024",
    readTime: "7 min read",
    image: "/blog/libdes-2.jpg",
    slug: "what-is-liberatory-design",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "At incluu, we believe in meeting people where they are and then guiding them to expand their comfort zones, abilities, and capacities. One of the most powerful frameworks we use in our work is Liberatory Design—a creative problem-solving approach that centers equity and designs for those who have been most marginalized.",
      "Liberatory Design emerged from the work of the National Equity Project and Stanford d.school, combining human-centered design thinking with a deep commitment to equity and liberation. It recognizes that traditional design processes, even well-intentioned ones, often perpetuate existing power imbalances and fail to address the root causes of inequity.",
      "The framework is built on several key principles: Notice and Reflect, which asks designers to examine their own identities, assumptions, and biases before beginning the design process. Empathize and Define challenges us to deeply understand the experiences of those most impacted by the problem we're trying to solve.",
      "Ideate and Prototype encourages bold, creative solutions that challenge existing systems rather than working within their constraints. Test and Learn emphasizes iterative improvement based on feedback from the communities most impacted. Throughout the process, designers are asked to constantly examine who holds power, who benefits, and who is harmed.",
      "What sets Liberatory Design apart from other design frameworks is its explicit focus on dismantling oppressive systems rather than merely accommodating them. It asks designers to consider not just 'Does this solution work?' but 'Does this solution advance liberation? Does it shift power? Does it heal harm?'",
      "In practice, this means involving marginalized communities not just as research subjects or test users, but as co-designers with real power over the design process. It means being willing to abandon solutions that perpetuate harm, even if they're technically effective. It means designing for systemic change, not just individual accommodation.",
      "As technology continues to shape every aspect of our lives, the need for liberatory approaches to design becomes ever more urgent. The question is not whether our designs will have social impact—they inevitably will. The question is whether that impact will advance liberation or perpetuate oppression.",
    ],
  },
  {
    id: 13,
    title: "The Importance of Intersectionality in Tech",
    description: "Why understanding intersectionality is essential for building equitable technology systems.",
    category: "Tech Equity",
    date: "April 5, 2024",
    readTime: "8 min read",
    image: "/blog/christina-wocintechchat-com-rmweulmcyxm-unsplash-1024x684-281-29-2.jpg",
    slug: "importance-intersectionality-in-tech",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Intersectionality, a term coined by legal scholar Kimberlé Crenshaw in 1989, describes how multiple forms of discrimination and disadvantage can overlap and compound. In the context of technology, understanding intersectionality is essential for building systems that serve all users equitably.",
      "Consider the example of facial recognition technology. We know that these systems perform poorly on darker-skinned faces. We also know they perform poorly on women's faces. But the intersection of these identities—dark-skinned women—experience the highest error rates of all. This isn't simply the sum of race bias plus gender bias; it's a unique form of harm that emerges at the intersection.",
      "The tech industry has historically struggled with diversity and inclusion, but even well-intentioned diversity efforts often fail to account for intersectionality. Hiring more women doesn't necessarily help Black women if workplace culture remains hostile to Blackness. Supporting LGBTQ+ employees doesn't necessarily help LGBTQ+ people with disabilities if accessibility is overlooked.",
      "When we design technology, we must consider not just individual identity categories but the many ways those identities intersect. A voice assistant that works well for able-bodied white men may fail for users who are elderly, have accents, use wheelchairs, or exist at multiple intersections of marginalization.",
      "Building intersectionally-aware technology requires diverse teams—not just demographically diverse, but diverse in lived experience and perspective. It requires research methods that specifically seek out users at intersections of marginalization. It requires testing protocols that disaggregate data by intersecting identities, not just single categories.",
      "Most importantly, building intersectionally-aware technology requires humility. No single person or team can anticipate every intersection of identity and experience. We must create systems that can learn and adapt, with robust feedback mechanisms that empower users to report when technology fails them.",
      "As technology becomes increasingly embedded in critical systems—healthcare, criminal justice, employment, housing—the stakes of getting intersectionality wrong continue to rise. We cannot afford to build technology that serves only the majority while failing those at the margins.",
    ],
  },
  {
    id: 14,
    title: "Equal Pay & Caregiving: How Covid19 Further Exacerbates Existing Inequities",
    description: "Examining how the pandemic deepened wage gaps and caregiving burdens for BIPOC women.",
    category: "Tech Equity",
    date: "April 4, 2024",
    readTime: "9 min read",
    image: "/blog/gris-zy-1920x1080-1.jpeg",
    slug: "equal-pay-caregiving-covid19-inequities",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "International Women's day is a day in which many celebrate the progress we're making towards equal pay and fair wages between men and women. Over more than a century, this day has been observed in February on the Julian calendar and March on the Gregorian calendar. What is encoded in the language-as is often the case-is that International Women's Day is actually only a marker of the progress being made to bridge the wage gap between white men and white women.",
      "Black women currently observe equal pay day in August—August 3rd, this year, and it has yet to become cause for celebration; we have had to work approximately 8 months into the new year just to earn the same amount of pay that white (Non-Hispanic) men earned last year.",
      "'Black women's gender pay gap has only closed three cents in 30 years, according to the National Women's Law Center. This disparity adds up to a typical loss of $24,110 dollars a year, totaling about $900,000 over a 40-year career.' - Fortune",
      "Why is this when Black women currently hold more post-secondary degrees percentage-wise than White women, Latinas, Asian/Pacific Islanders and Indigenous Peoples? BIPOC women disproportionately comprise roles in service industries placing them in a precarious position as COVID-19 ravaged the country.",
      "Not only is the exposure risk for COVID-19 greater for essential workers, but untreated (due to an increased probability of misdiagnosis) comorbidities pose an added risk. Additional risk factors that affect BIWOC are the likelihood that we, compared to our white counterparts, are underinsured, uninsured, or otherwise unable to take the time off of work for routine health screenings and adequate medical care, preventive or otherwise.",
      "BIPOC are literally forced to gamble with our lives everyday. The pandemic didn't create these inequities—it revealed and amplified them. As we rebuild, we have an opportunity to address these systemic issues rather than returning to a 'normal' that never worked for everyone.",
      "Technology plays a crucial role here. From healthcare AI that perpetuates diagnostic biases to hiring algorithms that replicate wage gaps, the systems we build either challenge or reinforce these inequities. We must choose to build systems that advance equity, not perpetuate harm.",
    ],
  },
  {
    id: 15,
    title: "As a Black Woman, I'm Either Hyper Visible or Utterly Unseen",
    description: "A personal reflection on the paradox of visibility faced by Black women in professional spaces.",
    category: "Tech Equity",
    date: "April 4, 2024",
    readTime: "7 min read",
    image: "/blog/1lhfbfkk64woxkzqw9fddig.jpeg",
    slug: "black-woman-hypervisible-or-unseen",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "As a Black woman, I exist in a paradox of visibility. In some spaces, I am hyper-visible—my presence noted, scrutinized, and often challenged. My mistakes are magnified, my qualifications questioned, my tone policed. I am seen, but through a lens distorted by stereotypes and assumptions.",
      "In other spaces, I am utterly unseen. My contributions are overlooked, my ideas attributed to others, my presence forgotten when opportunities arise. I speak and am not heard. I exist and am not acknowledged. This invisibility is its own form of violence.",
      "This paradox is not unique to me. Black women across industries report similar experiences—the exhausting oscillation between being too much and being not enough, between being hyper-surveilled and being overlooked. It is a form of psychological whiplash that exacts a heavy toll.",
      "In tech spaces, this paradox takes particular forms. I am visible when companies need to demonstrate diversity—trotted out for photos and panels—but invisible when decisions are made, resources allocated, promotions considered. I am visible when I make mistakes, but invisible when I succeed.",
      "The impact of this paradox extends beyond individual experience. When Black women are unseen, our insights and innovations are lost. When we are hyper-visible only through the lens of stereotype, our full humanity is denied. Both forms of distorted visibility cause harm—to us as individuals and to the organizations and communities that lose our full contributions.",
      "Addressing this paradox requires more than diversity initiatives or unconscious bias training. It requires fundamentally restructuring systems of power and perception. It requires white colleagues and leaders to examine their own seeing—what they notice, what they value, what they attribute to whom.",
      "For me, navigating this paradox has meant finding spaces where I can be fully seen—where my complexity is acknowledged, my contributions valued, and my humanity affirmed. These spaces are rare, which is why I work to create them through incluu and through my broader advocacy.",
    ],
  },
  {
    id: 16,
    title: "5 things Holding Organizations back from Transformative Change",
    description: "Common barriers that prevent organizations from achieving meaningful DEI progress and how to overcome them.",
    category: "Business Impact",
    date: "April 3, 2024",
    readTime: "10 min read",
    image: "/blog/good_cheap_fast-2.png",
    slug: "5-things-holding-organizations-back-transformative-change",
    author: "Destiny Fox Kanno",
    content: [
      "At incluu, LLC, we create brave spaces for life. To some, this concept may sound dreamy, ambitious, and a little 'millennial', but our work in the diversity, equity, and inclusion space at the intersection of human, tech, and civil rights has continued to expose the pitfalls organizations face when they do not fully embrace and commit to their DEI initiatives.",
      "The murder of George Floyd in May 2020 and the global Black Lives Matter protests that followed forced organizations to explore the concept of breaking down barriers in their peoples, practices, and products. In doing so, many sought and are seeking more fair and inclusive practices.",
      "Resources to grow inclusivity and belonging internally and externally are increasing daily, and yet many individuals and organizations still struggle to progress this work. Our team at incluu has over twenty collective years of experience working on various diversity, equity, and inclusion projects for accessibility, product, education, and across tech spaces. From that experience, we've learned that an organization's failure to achieve and reach its full potential for real, sustainable transformative change stems from five factors.",
      "1. Inability to see DEI work as mission-critical: Take this example: An organization has rallied to the call for more comprehensive changes by green-lighting the creation of a DEI committee, or perhaps a new Employee Resource Group. Hooray; this is a good first step as everything appears to be headed in the right direction. But is it? If DEI remains siloed from core business operations, it will never achieve transformative impact.",
      "2. Lack of psychological safety: Without psychological safety, employees cannot bring their full selves to work, cannot speak up about problems, and cannot take the risks necessary for innovation. Creating psychological safety requires sustained effort from leadership—not just policies, but consistent modeling of vulnerability, curiosity, and accountability.",
      "3. Insufficient resources and commitment: DEI work requires real investment—in time, in money, in personnel. Organizations that attempt to advance DEI on volunteer labor and minimal budgets signal that this work is not truly a priority. Transformative change requires transformative investment.",
      "4. Failure to center those most impacted: Effective DEI work must be informed by and accountable to those most impacted by inequity. When DEI initiatives are designed by and for the majority, they often perpetuate the very patterns they claim to address.",
      "5. Impatience with the pace of change: Transformative change is slow, nonlinear, and uncomfortable. Organizations that expect quick wins or give up at the first setback will never achieve meaningful progress. Sustainable change requires sustained commitment, even when progress is difficult to measure.",
    ],
  },
  {
    id: 17,
    title: "The Divisive Fallacy of Objective Truth",
    description: "Examining how claims of 'objectivity' often mask and perpetuate existing power structures.",
    category: "Tech Equity",
    date: "April 2, 2024",
    readTime: "7 min read",
    image: "/blog/the_divisive_fallacy_of_objective_truth-1.png",
    slug: "divisive-fallacy-objective-truth",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "In debates about equity and justice, we often encounter appeals to 'objective truth' or 'pure logic' as if these concepts exist outside of human experience and social context. But the idea of perfectly objective truth is itself a social construction—one that often serves to maintain existing power structures.",
      "This is not to say that facts don't exist or that all perspectives are equally valid. Rather, it is to recognize that what we consider 'objective' is always mediated by human perception, language, and social position. The questions we ask, the methods we use, the conclusions we draw—all are shaped by who we are and where we stand.",
      "In technology, claims of objectivity are particularly seductive and particularly dangerous. Algorithms are often presented as neutral and objective, when in reality they encode the biases of their creators and the inequities present in their training data. The appearance of objectivity makes these biases harder to see and harder to challenge.",
      "Consider credit scoring algorithms. They are presented as objective assessments of creditworthiness, but they perpetuate historical patterns of discrimination by using proxies for race like zip code and purchasing patterns. The veneer of mathematical objectivity makes the discrimination harder to identify and contest.",
      "When marginalized communities challenge these systems, they are often dismissed for being 'emotional' or 'subjective'—as if lived experience of harm is less valid than the abstract models that cause that harm. This dismissal is itself a tool of power, used to silence dissent and maintain the status quo.",
      "True rigor requires acknowledging positionality, not pretending it doesn't exist. It requires considering whose experiences are centered and whose are marginalized. It requires humility about the limits of our knowledge and openness to perspectives different from our own.",
      "The goal is not to abandon the pursuit of truth, but to recognize that truth-seeking is always a human endeavor, shaped by human perspectives and serving human purposes. When we acknowledge this, we can begin to ask: Whose truth? Truth in service of what? These are the questions that lead to more just and more rigorous inquiry.",
    ],
  },
  {
    id: 18,
    title: "We Stand in Unity with Our Asian Allies",
    description: "A statement of solidarity with Asian communities in the face of rising anti-Asian hate.",
    category: "Tech Equity",
    date: "April 1, 2024",
    readTime: "5 min read",
    image: "/blog/pexels-photo-5723322-1.jpeg",
    slug: "stand-in-unity-asian-allies",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "In the wake of rising anti-Asian violence and hate, we at incluu stand in solidarity with our Asian and Asian American colleagues, friends, and communities. The targeting of Asian communities—fueled by racist rhetoric and centuries of xenophobia—represents a fundamental threat to the multiracial democracy we are fighting to build.",
      "As a Black woman, I know that our liberations are intertwined. The same systems of white supremacy that target Asian communities also target Black communities, Indigenous communities, and all communities of color. We cannot achieve liberation separately; we must fight together.",
      "This solidarity is not just rhetorical. It requires action: calling out anti-Asian racism when we see it, supporting Asian-owned businesses, advocating for policies that protect vulnerable communities, and educating ourselves about the long history of anti-Asian discrimination in this country.",
      "It also requires honest reckoning with the ways that different communities of color have sometimes been pitted against each other. The model minority myth, for example, has been used to deny the reality of anti-Asian racism while simultaneously being weaponized against Black communities. We must reject these divisive narratives and build genuine solidarity.",
      "In the tech industry, Asian and Asian American workers face unique challenges—from the bamboo ceiling that limits advancement to the assumption that technical skills are innate rather than learned. These challenges intersect with other forms of marginalization for Asian women, LGBTQ+ Asians, and Asians with disabilities.",
      "At incluu, we are committed to building technology and organizations that serve all communities. This commitment requires centering those most marginalized—including Asian communities facing hate and violence. We will continue to advocate for inclusive design, equitable systems, and liberation for all.",
    ],
  },
  {
    id: 19,
    title: "What Is Intersectionality and Why Is It Important",
    description: "A foundational guide to understanding intersectionality and its relevance to equity work.",
    category: "Tech Equity",
    date: "March 7, 2024",
    readTime: "8 min read",
    image: "/blog/post1-1955x2048-2.jpg",
    slug: "what-is-intersectionality-why-important",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Intersectionality is a framework for understanding how different aspects of a person's social and political identities combine to create unique modes of discrimination and privilege. The term was coined by legal scholar Kimberlé Crenshaw in 1989 to describe how Black women's experiences of discrimination were not captured by looking at race and gender separately.",
      "Crenshaw used the metaphor of a traffic intersection to explain the concept. Just as a car accident at an intersection can be caused by traffic from any direction, discrimination at the intersection of multiple identities can be caused by any of those identities—and the intersection itself creates unique vulnerabilities.",
      "Consider a Black woman experiencing workplace discrimination. If the company has Black men in leadership and white women in leadership, her discrimination claim may be dismissed because 'the company clearly doesn't discriminate against Black people or women.' But discrimination against Black women specifically falls through the cracks of single-axis analysis.",
      "Intersectionality is not just an academic concept—it has profound practical implications for how we design systems, policies, and technologies. When we fail to consider intersectionality, we often create solutions that help the most privileged members of marginalized groups while leaving the most vulnerable behind.",
      "In tech, intersectional analysis reveals how algorithmic systems can cause unique harms at identity intersections. Voice recognition systems may work well for white men and reasonably well for white women and Black men—but fail specifically for Black women, whose voices exist at the intersection of patterns not well represented in training data.",
      "Applying intersectionality to equity work means disaggregating data by multiple dimensions, not just one. It means centering those at the margins of margins. It means recognizing that 'one size fits all' solutions rarely fit those with the most complex, intersecting needs.",
      "Understanding intersectionality also means recognizing that identities are not just sources of disadvantage—they are also sources of knowledge, perspective, and strength. Those who navigate multiple marginalizations often develop unique insights and capabilities that are valuable to organizations and communities.",
    ],
  },
  {
    id: 20,
    title: "Racism and The Wellness Industry",
    description: "Examining how the wellness industry often excludes and harms BIPOC communities.",
    category: "Wellness",
    date: "March 6, 2024",
    readTime: "7 min read",
    image: "/blog/tanaka-pendeke-o9gfrup1l9w-unsplash-scaled-2.jpg",
    slug: "racism-and-wellness-industry",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The wellness industry presents itself as universally beneficial—promoting health, mindfulness, and self-care for all. But a closer examination reveals an industry built on exclusion, appropriation, and the perpetuation of white-centered beauty and health standards.",
      "From yoga studios that erase the practice's South Asian origins to meditation apps that ignore the Buddhist traditions they draw from, the wellness industry consistently extracts value from BIPOC cultures while excluding BIPOC people from leadership and participation.",
      "The imagery of wellness is overwhelmingly white, thin, and able-bodied. When BIPOC bodies do appear, they are often tokenized or exoticized—present to signal diversity without challenging the underlying whiteness of the space. This visual exclusion sends a clear message about who wellness is for.",
      "Beyond representation, the wellness industry often perpetuates harmful ideas about health that disproportionately impact BIPOC communities. The emphasis on individual responsibility for health ignores the systemic factors—environmental racism, healthcare discrimination, food apartheid—that create health disparities.",
      "For Black women specifically, the wellness industry's focus on stress reduction and self-care can feel like a cruel joke when the primary sources of our stress—racism, sexism, economic precarity—are left unaddressed. We are told to meditate and exercise while the systems that harm us remain unchanged.",
      "This is not to say that wellness practices are inherently harmful or that BIPOC people should avoid them. Rather, it is a call for a wellness paradigm that acknowledges structural barriers to health, honors the cultural origins of healing practices, and recognizes that true wellness cannot be achieved through individual action alone.",
      "At incluu, we advocate for wellness approaches that center BIPOC communities, address systemic harms, and recognize rest and healing as forms of resistance. Wellness should be a tool for liberation, not another industry that extracts from marginalized communities while excluding them from its benefits.",
    ],
  },
  {
    id: 21,
    title: "Race Norming and Bioethics",
    description: "Examining the racist practice of race norming in medical algorithms and its devastating consequences.",
    category: "AI Governance",
    date: "March 5, 2024",
    readTime: "8 min read",
    image: "/blog/trnava-university-lr_mkznghuu-unsplash-scaled-2.jpg",
    slug: "race-norming-and-bioethics",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Race norming—the practice of adjusting medical test results based on a patient's race—has been embedded in healthcare algorithms for decades. These adjustments, often based on debunked racial science, have resulted in Black patients receiving less aggressive treatment, being denied organ transplants, and dying from conditions that could have been treated.",
      "One of the most well-known examples is the eGFR (estimated Glomerular Filtration Rate) equation used to assess kidney function. For years, this equation included a 'race correction' that assumed Black patients had higher muscle mass, resulting in artificially inflated kidney function scores for Black patients—and delayed referrals for dialysis and transplant.",
      "The NFL's use of race norming in concussion settlements is another egregious example. The league assumed Black players started with lower cognitive function, making it harder for them to demonstrate cognitive decline and qualify for compensation. This practice was only ended after widespread outcry and legal challenges.",
      "These practices are rooted in the long, ugly history of scientific racism—the use of pseudoscience to justify racial hierarchy and oppression. From Samuel Morton's skull measurements to the Tuskegee syphilis study, medicine has repeatedly been used as a tool of white supremacy.",
      "The integration of race norming into algorithmic systems is particularly dangerous because it gives these racist practices the appearance of scientific objectivity. When a computer outputs a treatment recommendation, patients and even providers may assume it is unbiased—not recognizing the racist assumptions encoded in the algorithm.",
      "Addressing race norming requires systematic review of medical algorithms, removal of race-based adjustments not supported by evidence, and recognition that race is a social construct that does not map onto biological difference in the ways these algorithms assume.",
      "More fundamentally, it requires reckoning with the ongoing legacy of scientific racism in medicine and building healthcare systems that center the needs and experiences of those who have been most harmed by medical racism.",
    ],
  },
  {
    id: 22,
    title: "Black Excellence and the Low Expectations of White Supremacy",
    description: "Examining how 'Black excellence' narratives can unintentionally reinforce white supremacist frameworks.",
    category: "Tech Equity",
    date: "March 4, 2024",
    readTime: "7 min read",
    image: "/blog/blog-post-image-template-2.png",
    slug: "black-excellence-low-expectations-white-supremacy",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The celebration of 'Black excellence' has become a common way of highlighting Black achievement and countering negative stereotypes. And there is much to celebrate—Black people have achieved extraordinary things despite the persistent headwinds of racism and discrimination.",
      "But I want to offer a complicating perspective: the narrative of Black excellence, while well-intentioned, can sometimes reinforce the very white supremacist frameworks it seeks to challenge. When we feel the need to prove Black worth through exceptional achievement, we implicitly accept the premise that Black worth requires proving.",
      "White supremacy sets impossibly high bars for Black people—we must be twice as good to get half as far. When we celebrate only those who clear these bars, we inadvertently affirm the legitimacy of the bars themselves. We suggest that Black people who are merely average—who are human, with human limitations—are somehow insufficient.",
      "Moreover, the focus on individual Black excellence can obscure systemic analysis. When we attribute Black achievement to exceptional individual qualities, we may miss the structural changes needed to ensure that Black people don't need to be exceptional to survive and thrive.",
      "This is not a call to stop celebrating Black achievement. It is a call to interrogate the frameworks within which we celebrate. Can we honor Black accomplishment without implying that accomplishment is necessary for Black dignity? Can we recognize systemic barriers while also celebrating those who overcome them?",
      "In tech, this tension is particularly acute. The celebration of Black tech leaders and entrepreneurs is important and necessary. But it should not come at the cost of systemic critique or create the impression that individual success negates the need for structural change.",
      "True liberation is not about proving that some Black people can achieve by white standards despite the odds. It is about creating a world where all Black people can flourish according to their own standards—a world where Black humanity is assumed, not proven.",
    ],
  },
  {
    id: 23,
    title: "The Spirit of Juneteenth is Acknowledgement",
    description: "Reflecting on the meaning of Juneteenth and the ongoing struggle for Black liberation.",
    category: "Tech Equity",
    date: "March 3, 2024",
    readTime: "6 min read",
    image: "/blog/the-spirit-of-juneteenth-1.png",
    slug: "spirit-of-juneteenth-acknowledgement",
    author: "Destiny Fox Kanno",
    content: [
      "<strong>Recognizing <a href='https://www.woojr.com/learn-about-juneteenth-for-kids-a-celebration-of-freedom/' target='_blank' rel='noopener noreferrer'>Juneteenth</a> as a National Holiday is not a solution to ending racism. It's a bandaid, a temporary fix to a wound at which we have given only a cursory triage. Gatekeeping humanity by only granting the privilege of it being recognized, is wrong. There lies the audacity of racism: to believe freedom can be taken and given at one's will and without recourse.</strong>",
      "<strong>Establishing Juneteenth as a federal holiday is an acknowledgement of slavery, which as an institution, has morphed appearances and changed tactics often in order to remain viable in today's society. Juneteenth recognizes the subjugation of people which continued long after it was supposed to have ended in the United States. It is also an acknowledgement of the history of horrible injustices lobbied against the whole of Black communities around the globe at the hands of the imperialistic abuse of power so often chosen by governments more concerned with being strong (and therefore right) rather than being compassionate and humane.</strong>",
      "<strong>Acknowledgement is only the beginning.</strong>",
      "<a href='https://www.teenvogue.com/story/white-supremacy-is-the-problem' target='_blank' rel='noopener noreferrer'><strong>The Institution of White Supremacy</strong></a> continues to marginalize anyone different. It has deemed the needs of non-white people unimportant. Instead of transformative changes like <a href='https://www.brookings.edu/blog/up-front/2020/12/08/the-black-white-wealth-gap-left-black-households-more-vulnerable/' target='_blank' rel='noopener noreferrer'>eradicating systems of inequal wealth distribution</a>, we get a holiday. A single day off for most Americans in which we are expected to contemplate the history of slavery and its lasting effects.",
      "True acknowledgement requires reckoning. It requires examining how our institutions, our technologies, and our practices perpetuate the legacy of slavery and subsequent systems of oppression. It requires asking uncomfortable questions and being willing to fundamentally change.",
      "This Juneteenth and every day, let us commit to acknowledgement that leads to action. Let us build technologies that advance Black liberation rather than perpetuating oppression. Let us create organizations where Black people can thrive, not just survive. Let us honor those who fought for freedom by continuing that fight today.",
      "<strong>About The Author:</strong> <a href='https://www.incluu.us/author/destiny/' target='_blank' rel='noopener noreferrer'>Destiny Fox Kanno</a> (Des-tuh-knee Foks Kah-no), going by she/her/they/them, is an Incluu Consultant whose work in Account Management, Product & Project Management, and Customer Service lends itself to various diverse projects at Incluu. Destiny is an avid civil rights and social justice advocate, who recently having published a guide on how to support Black people after the George Floyd shooting, continues to raise awareness about equity and inclusion causes and issues around the globe.",
    ],
  },
  {
    id: 24,
    title: "60 Minutes and (En)Coded Bias",
    description: "Reflecting on the 60 Minutes feature on AI bias and the ongoing work to address algorithmic discrimination.",
    category: "AI Governance",
    date: "March 2, 2024",
    readTime: "7 min read",
    image: "/blog/joy_buolamwini_-_wikimania_2018_01-1-2.jpg",
    slug: "60-minutes-encoded-bias",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "When 60 Minutes aired its segment on AI bias featuring the groundbreaking work of Joy Buolamwini and the Algorithmic Justice League, it marked a significant moment in bringing algorithmic discrimination to mainstream awareness. But awareness is only the beginning.",
      "Joy Buolamwini's research revealed what many BIPOC people already knew from lived experience: facial recognition systems don't see us accurately. Her Gender Shades project demonstrated that commercial facial recognition systems had error rates of up to 34.7% for dark-skinned women, compared to less than 1% for light-skinned men.",
      "This research sparked important conversations and policy changes. Some cities have banned government use of facial recognition. Some tech companies have pulled back from selling these systems to law enforcement. But the underlying problems—biased datasets, homogeneous development teams, lack of accountability—persist across AI systems.",
      "The documentary 'Coded Bias' further explored these issues, following Buolamwini and other activists fighting for algorithmic justice. It showed how AI systems are being deployed in high-stakes contexts—hiring, lending, policing, healthcare—with minimal oversight and devastating consequences for marginalized communities.",
      "What strikes me most about this work is how it centers the voices and experiences of those most impacted by algorithmic harm. This is not abstract academic research—it is research rooted in lived experience and oriented toward justice.",
      "At incluu, we are inspired by this work and committed to continuing it. We advocate for algorithmic accountability, for diverse and inclusive AI development teams, for regulatory frameworks that protect vulnerable communities, and for a fundamental reorientation of AI development toward liberation rather than oppression.",
      "The 60 Minutes segment was a moment of visibility. But the real work happens in the daily choices of researchers, developers, policymakers, and advocates fighting for algorithmic justice. That work continues.",
    ],
  },
  {
    id: 25,
    title: "From Invisibility to Radical Empathy",
    description: "A journey from being unseen to building bridges of understanding through radical empathy.",
    category: "Wellness",
    date: "March 1, 2024",
    readTime: "8 min read",
    image: "/blog/0ha5_gjflj6n_okrx.jpeg",
    slug: "from-invisibility-to-radical-empathy",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "My journey in tech equity and inclusion began, in many ways, with experiences of invisibility. As a Black woman with a disability navigating predominantly white, able-bodied spaces, I learned early what it meant to be overlooked, dismissed, and unseen.",
      "But invisibility taught me something valuable: the importance of truly seeing others. When you know what it feels like to be unseen, you develop a heightened awareness of who else might be invisible in any given space. You learn to look for who is missing, whose voice is absent, whose needs are unmet.",
      "This awareness led me to what I call radical empathy—a practice of deeply and intentionally working to understand experiences different from our own. Radical empathy goes beyond sympathy (feeling for someone) or even standard empathy (feeling with someone). It requires actively working to understand perspectives that may be unfamiliar or even uncomfortable.",
      "Radical empathy is not passive. It requires effort, humility, and a willingness to be changed by what we learn. It means setting aside our assumptions and truly listening. It means believing people when they describe their experiences, even when those experiences differ from our own.",
      "In my work at incluu, radical empathy is foundational. We cannot design inclusive technologies without deeply understanding the experiences of those who have been excluded. We cannot build equitable organizations without empathizing with those who have been marginalized within them.",
      "But radical empathy must be accompanied by action. Understanding someone's experience without working to change the conditions that create that experience is incomplete at best, extractive at worst. Empathy without action can become a form of emotional tourism—visiting others' pain without commitment to alleviating it.",
      "From invisibility, I have built a practice of radical empathy. From radical empathy, I work toward radical action—the transformation of systems, technologies, and organizations to center those who have been most marginalized. This is the work of incluu, and it is the work I invite you to join.",
    ],
  },
]

// Helper functions
export function getPostBySlug(slug: string): BlogPost | undefined {
  return blogPosts.find(post => post.slug === slug)
}

export function getAllPostSlugs(): string[] {
  return blogPosts.map(post => post.slug)
}

export function getAllCategories(): string[] {
  const categories = new Set(blogPosts.map(post => post.category))
  return ['All', ...Array.from(categories)]
}

export function getPostsByCategory(category: string): BlogPost[] {
  if (category === 'All') return blogPosts
  return blogPosts.filter(post => post.category === category)
}
