export interface BlogPost {
  id: number
  title: string
  description: string
  category: string
  date: string
  readTime: string
  image: string
  slug: string
  author: string
  content: string[]
}

export const blogPosts: BlogPost[] = [
  {
    id: 1,
    title: "EU AI Act: A Comprehensive Guide for 2026",
    description: "Understanding the key provisions, compliance requirements, and implementation timeline of the EU's landmark AI regulation.",
    category: "Compliance",
    date: "January 15, 2026",
    readTime: "8 min read",
    image: "/blog/eu-ai-act-leaders.jpg",
    slug: "eu-ai-act-guide-2026",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The EU AI Act represents the most comprehensive AI regulation globally, and 2026 marks a critical year for compliance. Organizations deploying AI systems in the European Union must understand their obligations and take proactive steps to ensure compliance. This landmark legislation will fundamentally reshape how businesses develop, deploy, and maintain artificial intelligence systems across all sectors.",
      "As someone who has spent over two decades at the intersection of technology and policy, I've watched this regulation evolve from early proposals to the comprehensive framework we see today. The Act didn't emerge in a vacuum—it's the culmination of years of growing concern about AI's impact on fundamental rights, safety, and democratic values.",
      "Understanding the Risk-Based Approach: The Act categorizes AI systems into four distinct risk levels, each with different compliance obligations. Unacceptable risk systems are outright banned—these include social scoring systems, real-time biometric identification in public spaces (with limited exceptions), and AI that manipulates human behavior to circumvent free will. High-risk systems face the most stringent requirements and include AI used in critical infrastructure, education, employment, essential services, law enforcement, and border management.",
      "Limited risk systems, such as chatbots and deepfakes, must meet transparency requirements—users must be informed they're interacting with AI. Minimal risk systems, which constitute the vast majority of AI applications, face no specific regulatory requirements under the Act, though general principles of responsible AI development still apply.",
      "Key Compliance Requirements for High-Risk Systems: Organizations deploying high-risk AI must implement comprehensive risk management systems that identify, analyze, evaluate, and mitigate risks throughout the AI lifecycle. This isn't a one-time assessment—it requires ongoing monitoring and updates as the system evolves and new risks emerge.",
      "Technical documentation requirements are extensive. You must maintain detailed records of the system's purpose, design specifications, training methodologies, data governance practices, and performance metrics. This documentation must be sufficient for authorities to assess compliance and must be updated whenever significant changes occur.",
      "Data governance is particularly critical. The Act requires that training, validation, and testing datasets be relevant, representative, and free from errors. For high-risk systems, you must implement measures to examine potential biases and ensure data quality. This is where many organizations struggle—historical data often encodes past discrimination, and addressing this requires intentional intervention.",
      "Human oversight requirements ensure that AI systems can be effectively supervised by humans. This includes implementing 'stop' buttons, designing systems so humans can understand their outputs, and ensuring operators are trained to identify anomalies and potential risks.",
      "Timeline and Penalties: The Act's provisions are being phased in over several years. Prohibitions on unacceptable-risk AI took effect in early 2025. Requirements for general-purpose AI models became applicable in August 2025. High-risk system requirements will be fully enforceable by August 2026, making this year critical for compliance preparation.",
      "Penalties for non-compliance are severe: up to €35 million or 7% of global annual turnover for violations related to prohibited AI practices; up to €15 million or 3% for other violations. For many organizations, these penalties could be existential. But beyond financial penalties, non-compliance risks reputational damage, loss of market access, and exclusion from an increasingly ethics-conscious supply chain.",
      "Strategic Recommendations: Begin with a comprehensive AI inventory. Many organizations are surprised to discover how many AI systems they actually deploy—from obvious applications like recommendation engines to less visible uses in HR screening, fraud detection, and customer service. Every system needs classification and potential compliance assessment.",
      "Establish cross-functional governance structures now. AI compliance isn't just a technical problem—it requires coordination between legal, compliance, engineering, data science, and business teams. Create clear lines of responsibility and decision-making authority before regulatory pressure intensifies.",
      "Invest in documentation infrastructure. The Act's requirements for technical documentation, logging, and record-keeping are substantial. Organizations that build these capabilities now will be better positioned for compliance and will also benefit from improved operational visibility and debugging capabilities.",
      "The organizations that thrive under the EU AI Act will be those that view compliance not as a burden but as an opportunity to build trust, differentiate from competitors, and create AI systems that genuinely serve human flourishing. The regulatory landscape is shifting—the question is whether your organization will lead or follow.",
    ],
  },
  {
    id: 2,
    title: "Building Inclusive AI Products: A Framework",
    description: "Practical strategies for integrating inclusion principles throughout the AI product development lifecycle.",
    category: "Product Development",
    date: "January 8, 2026",
    readTime: "10 min read",
    image: "/blog/disability-innovation-driver.jpg",
    slug: "inclusive-ai-framework",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Building inclusive AI products requires intentional effort at every stage of the development lifecycle, from initial conception through deployment and ongoing maintenance.",
      "The foundation of inclusive AI begins with diverse representation in the teams building these systems. Research consistently shows that homogeneous teams produce AI systems that fail to account for the needs and experiences of marginalized communities.",
      "Data collection and curation represent critical junctures where bias can be introduced or mitigated. Teams must carefully consider whose data is included, whose is excluded, and what historical inequities might be encoded in training datasets.",
      "Testing and validation must go beyond traditional metrics to include fairness evaluations across different demographic groups. This includes testing for disparate impact, examining edge cases, and engaging affected communities in the evaluation process.",
      "Inclusive design also means considering accessibility from the outset. AI interfaces should be usable by people with disabilities, and AI systems should not create new barriers to access or participation.",
      "Finally, inclusive AI requires ongoing monitoring and accountability mechanisms. Organizations must be prepared to identify and address harms that emerge after deployment, with clear channels for affected individuals to report concerns.",
    ],
  },
  {
    id: 3,
    title: "The Business Case for Responsible AI",
    description: "How ethical AI practices drive competitive advantage, reduce risk, and create sustainable value.",
    category: "Business Strategy",
    date: "December 18, 2025",
    readTime: "8 min read",
    image: "/blog/building-ethical-ai-systems.jpg",
    slug: "business-case-responsible-ai",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The business case for responsible AI has never been stronger. As regulatory frameworks mature and public awareness grows, organizations that prioritize ethical AI practices are gaining significant competitive advantages.",
      "Risk mitigation represents one of the most tangible benefits. AI failures can result in regulatory penalties, litigation, and reputational damage that far exceeds the cost of implementing responsible AI practices from the outset.",
      "Consumer trust is increasingly tied to responsible AI practices. Studies show that customers are more likely to engage with and remain loyal to organizations that demonstrate commitment to ethical AI use.",
      "Responsible AI practices also drive innovation. Constraints often spark creativity, and the requirement to build fair, transparent, and accountable AI systems pushes teams to develop novel approaches that benefit all users.",
      "Talent acquisition and retention are also impacted. Top AI researchers and engineers increasingly want to work for organizations whose values align with their own, making responsible AI a competitive advantage in the war for talent.",
      "The investment community is taking notice as well. ESG considerations now explicitly include AI ethics, and organizations with strong responsible AI practices are viewed more favorably by investors focused on long-term value creation.",
    ],
  },
  {
    id: 4,
    title: "Navigating AI Bias: Detection and Mitigation",
    description: "Technical and organizational approaches to identifying and addressing bias in AI systems.",
    category: "Technical",
    date: "December 5, 2025",
    readTime: "15 min read",
    image: "/blog/roi-accessible-technology.jpg",
    slug: "ai-bias-detection-mitigation",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "AI bias remains one of the most significant challenges facing the field, with documented cases of discriminatory outcomes in hiring, lending, healthcare, and criminal justice systems.",
      "Detection begins with understanding the multiple forms bias can take: historical bias embedded in training data, representation bias from non-representative samples, measurement bias from flawed proxies, and algorithmic bias introduced during model development.",
      "Technical approaches to bias detection include statistical parity analysis, examining outcomes across protected groups, and using interpretability tools to understand how models make decisions.",
      "Mitigation strategies can be applied at different stages: pre-processing techniques that balance or transform training data, in-processing methods that constrain learning algorithms, and post-processing adjustments to model outputs.",
      "However, technical solutions alone are insufficient. Organizations must also address the organizational and societal factors that contribute to biased AI, including lack of diversity in AI teams and insufficient engagement with affected communities.",
      "Ongoing monitoring is essential, as bias can emerge or shift over time as data distributions change and AI systems interact with the real world in unexpected ways.",
    ],
  },
  {
    id: 5,
    title: "AI Governance Structures That Work",
    description: "Lessons from organizations successfully implementing AI ethics boards and governance frameworks.",
    category: "Governance",
    date: "November 22, 2025",
    readTime: "11 min read",
    image: "/blog/algorithmic-bias-detection.jpg",
    slug: "ai-governance-structures",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Effective AI governance requires more than good intentions—it demands clear structures, defined responsibilities, and mechanisms for accountability.",
      "Successful AI ethics boards share several characteristics: genuine authority to influence or halt projects, diverse membership including external perspectives, clear mandates and decision-making processes, and direct access to senior leadership.",
      "Governance frameworks must be integrated into existing organizational processes rather than bolted on as an afterthought. This means incorporating ethical review into project approval workflows, budgeting processes, and performance evaluations.",
      "Documentation is critical. Organizations need clear records of AI system capabilities, limitations, training data, and deployment contexts. This documentation supports both internal governance and external accountability.",
      "Training and culture change are equally important. All employees involved in AI development and deployment need to understand their responsibilities and have the skills to identify and escalate ethical concerns.",
      "Finally, effective governance includes mechanisms for external input and accountability, whether through formal audits, stakeholder advisory groups, or public reporting on AI practices and outcomes.",
    ],
  },
  {
    id: 6,
    title: "The Future of AI Regulation: Global Trends",
    description: "Analyzing emerging regulatory approaches across jurisdictions and their implications for global AI development.",
    category: "Compliance",
    date: "November 10, 2025",
    readTime: "9 min read",
    image: "/blog/rest-resistance-wellness.jpg",
    slug: "future-ai-regulation-global",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "AI regulation is evolving rapidly across the globe, with different jurisdictions taking varied approaches that reflect their unique legal traditions, economic interests, and societal values.",
      "The EU's AI Act has set a high-water mark for comprehensive regulation, but other jurisdictions are developing their own frameworks. The US has taken a more sector-specific approach, while China has focused on specific applications like recommendation algorithms and deepfakes.",
      "Emerging economies are also entering the regulatory landscape, often drawing on elements from multiple existing frameworks while adapting them to local contexts and priorities.",
      "For global organizations, this patchwork of regulations creates significant compliance challenges. Operating across jurisdictions requires understanding not just the letter of various laws but their underlying principles and enforcement priorities.",
      "Interoperability and mutual recognition arrangements are beginning to emerge, offering some hope for reduced compliance complexity. However, fundamental differences in approach—particularly around government access to data—may limit harmonization.",
      "Forward-thinking organizations are advocating for clear, consistent global standards while building flexibility into their AI governance frameworks to adapt to evolving requirements across jurisdictions.",
    ],
  },
  {
    id: 7,
    title: "Inclusive Design Patterns for AI Interfaces",
    description: "Design principles and patterns for creating AI-powered experiences that work for everyone.",
    category: "Design",
    date: "October 28, 2025",
    readTime: "13 min read",
    image: "/blog/inclusive-design-patterns.jpg",
    slug: "inclusive-design-patterns-ai",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "As AI becomes increasingly embedded in digital experiences, the need for inclusive design patterns specific to AI interfaces has never been greater.",
      "Transparency is a foundational principle. Users should understand when they're interacting with AI, what data is being used, and how decisions are being made. This doesn't mean exposing technical complexity, but rather providing meaningful explanations appropriate to context and audience.",
      "Control and agency are equally important. Users should be able to adjust, override, or opt out of AI-driven features. Default settings should be conservative, with more invasive AI features requiring explicit user activation.",
      "Error handling in AI systems requires special consideration. Unlike traditional software with predictable failure modes, AI systems can fail in unexpected ways. Interfaces should gracefully handle uncertainty, communicate limitations honestly, and provide clear paths to human assistance.",
      "Accessibility considerations for AI interfaces include ensuring that AI-generated content meets accessibility standards, that voice interfaces work for users with speech differences, and that AI features don't create new barriers for users with disabilities.",
      "Testing inclusive AI interfaces requires going beyond standard usability testing to include diverse participants and specifically probe for differential experiences across user groups.",
    ],
  },
  {
    id: 8,
    title: "Ethical AI and Smart Lock Systems",
    description: "Exploring the intersection of AI-powered security systems and the biases that can make them less secure for some users.",
    category: "Tech Equity",
    date: "April 30, 2024",
    readTime: "12 min read",
    image: "/blog/amol-tyagi-0juktkotkpu-unsplash-1638x2048-1.jpg",
    slug: "ethical-ai-and-smart-lock-systems",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "I recently sat down with a group to discuss the pros and cons of emerging technologies from my perspective as both anthropologist and ethical technologist; specifically, smart lock systems. For those who may be unfamiliar with smart lock systems, they are a relatively new technological advancement that uses image and facial recognition software to enable users entry to businesses and residences thereby eliminating physical keys; this technology is believed to increase safety and ease of accessibility.",
      "No more misplaced and lost keys, costly locksmith services, and the ease of allowing temporary and/or limited access to vendors, guests, and service providers. These are the pros and admittedly, they are cost-efficient, time-saving, and an added convenience for some – perhaps, many.",
      "There is a misconception that AI is godlike, infallible even; but AI is a product of wholly fallible human design. Coded into the complex algorithms are the same biases we deal with in our day to day human experiences. Laypersons are more apt to buy into a science they don't fully understand and this leaves an already over-policed, vulnerable faction of the population at a heightened risk of unprecedented, unmitigated harm.",
      "Within the past month, a <a href='https://www.usatoday.com/story/news/nation/2023/05/30/ralph-yarl-shooting-walks-brain-injury-event/70267933007/' target='_blank' rel='noopener noreferrer'>Black sixteen year old was seriously wounded</a> after being shot by a White homeowner for ringing his doorbell in error. It is not only reasonable to suspect, but to assert the homeowner reacted with such heightened hostility towards the error and minor inconvenience due to his own preconceived notions about race.",
      "What, then, do we do when there is a data error in AI, in smart lock technology? If human error is met with such lethal force, what does the future look like when we add in smart lock technology, which has not been adequately tested on people of color?",
      "The fact is that many smart lock systems on the market today have not been adequately tested on people of color. This creates a security vulnerability that disproportionately affects certain communities while being marketed as a universal solution.",
      "Fight to be in the room where it happens. Your lived experience and perspective matter. Your voices matter. And at the very least, we must be vigilant about these technologies and advocate for more inclusive testing and development practices.",
      "<strong>About The Author:</strong> <a href='https://www.incluu.us/author/drdede/' target='_blank' rel='noopener noreferrer'>Dr. Dédé Tetsubayashi</a> (Deh-deh Teh-tsu-bye-ya-she) expertise is DEI + product + business value and integrating them into a team and organization's best practices. She has extensive experience building frameworks and guidelines to integrate product inclusion into the development process, and driving adoption as an integral portion of phased and prioritized roadmaps for teams to execute against.",
    ],
  },
  {
    id: 9,
    title: "The Pitfalls of Adversarial Clothing",
    description: "How attempts to evade AI surveillance through fashion create new problems and who bears the risk.",
    category: "Tech Equity",
    date: "April 30, 2024",
    readTime: "7 min read",
    image: "/blog/adversarial-clothing.png",
    slug: "pitfalls-of-adversarial-clothing",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "When it comes to equity and inclusive design, there are two main components at odds with a social concern and tech firm's design. There are two new areas at the cross section of human centered design and what a social concern will fuel a tech business opportunity.",
      "Now we have smart, AI savvy consumers as well as tech savvy consumers, who are unwittingly subscribing to a way of evading facial recognition by dressing in very specific patterns. The tech firm sees an opportunity to bring about a change.",
      "The first issue with facial recognition technology and with adversarial clothing, like a hoodie, is that not all AI facial recognition systems are created equally. In fact, it's fair to say that some systems should be scrapped entirely given their poor design and high error rates particularly for darker-skinned individuals.",
      "Essentially, adversarial clothing is meant to make it harder for AI systems to track you. But here's the problem: these solutions put the burden on individuals to protect themselves from surveillance rather than addressing the underlying problems with these systems.",
      "Moreover, wearing adversarial clothing could actually draw more attention in certain contexts, potentially flagging the wearer for additional scrutiny. It's a solution that creates new problems while failing to address root causes.",
      "We need to be asking harder questions about why these surveillance systems exist in the first place, who they serve, and whether the trade-offs in privacy and equity are worth the purported benefits in security.",
    ],
  },
  {
    id: 10,
    title: "Facial Recognition and Racial Bias",
    description: "Examining the documented failures of facial recognition technology and their disproportionate impact on communities of color.",
    category: "Tech Equity",
    date: "April 26, 2024",
    readTime: "9 min read",
    image: "/blog/ariel-sion-i7v-btpnktg-unsplash-2048x1365-2.jpg",
    slug: "facial-recognition-and-racial-bias",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "In an ironic sense, it feels like issues that I've been yammered by pundits to debate Williams, Michael Brown, others, and Breyer have now suddenly to be believed with most people fairly well. And this isn't the exception of when things fairly well.",
      "These are important discussions to note. Let me give you a fact based example from 2018 when ACLU tested Amazon's facial recognition software Rekognition against members of Congress. The results were alarming.",
      "ACLU found that false matches came back for 28 lawmakers when compared against 25,000 mugshot photos. These false match rates were disproportionately high for people of color—and this was testing against some of the most photographed faces in America.",
      "Dr. Joy Buolamwini's research at MIT has been foundational in exposing these disparities. Her Gender Shades project demonstrated that commercial facial recognition systems had error rates of up to 34.7% for darker-skinned women compared to 0.8% for lighter-skinned men.",
      "The real-world consequences of these failures are severe. Robert Williams was wrongfully arrested in Detroit based on a faulty facial recognition match. He spent 30 hours in custody for a crime he didn't commit—a clear example of how biased AI can destroy lives.",
      "Cities like San Francisco, Boston, and Portland have banned government use of facial recognition technology. But many jurisdictions continue to deploy these flawed systems, disproportionately impacting the communities they claim to protect.",
    ],
  },
  {
    id: 11,
    title: "Digital Blackface: Are you complicit?",
    description: "Understanding the phenomenon of digital blackface and its perpetuation of harmful stereotypes online.",
    category: "Tech Equity",
    date: "April 7, 2024",
    readTime: "15 min read",
    image: "/blog/priscilla-du-preez-bjhuu6bpuza-unsplash-2048x1365-2.jpg",
    slug: "digital-blackface-are-you-complicit",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "<em>'[…] <a href='https://theawl.com/memes-and-misogynoir-c3fb3506613d' target='_blank' rel='noopener noreferrer'>digital blackface</a> is used to describe various types of minstrel performance that become available in cyberspace. Blackface minstrelsy is a theatrical tradition dating back to the early 19th century, in which performers blacken themselves up with costume and behaviors to act as black caricatures. The performances put society's most racist sensibilities on display and in turn fed them back to audiences to intensify these feelings and disperse them across culture.'</em> — Lauren Michele Jackson, Teen Vogue",
      "For those of us at the <a href='https://www.dr-dede.com/' target='_blank' rel='noopener noreferrer'>forefront of the fight for liberation</a>, the obstacles seem endless. It would appear that every facet of our daily existence and interactions are marred by pervasive influence of white supremacy–or rather, 'white supremacist delusion' as <a href='https://en.wikipedia.org/wiki/Sonya_Renee_Taylor' target='_blank' rel='noopener noreferrer'>Sonya Renee Taylor</a> has coined it. We have long since uncovered the truth about the social construct of race, but knowing better and living in that truth don't always align.",
      "Based on data compiled by <a href='https://www.statista.com/' target='_blank' rel='noopener noreferrer'>Statista</a>, it is estimated that in 2021 the average American spent 8+ hours on digital media daily, communicating with people from all walks of life, and from all over the world. A third of your day, everyday, is either an opportunity for harm or harm reduction and liberation.",
      "We've all seen it so much that in many ways, we've become desensitized to it. We may even participate in this behavior without understanding the implications or impact. Digital blackface manifests in many ways: using GIFs and memes featuring Black people to express emotions, adopting African American Vernacular English (AAVE) in online spaces, or creating avatars with Black features.",
      "The key question we must ask ourselves: Are you complicit? When you use that reaction GIF of a Black person making an exaggerated expression, you're participating in a digital form of minstrelsy. These images reduce Black people to their most emotional, expressive moments – often reinforcing stereotypes about Black expressiveness and emotionality.",
      "This isn't about policing humor or limiting expression. It's about understanding the historical context of how Black bodies have been used for entertainment without consent, compensation, or consideration. It's about recognizing how these seemingly innocent digital interactions perpetuate harmful narratives.",
      "Being mindful about the images we share online is part of building a more equitable digital culture. It requires us to think critically about whose images we're using, in what context, and whether our usage perpetuates harmful stereotypes.",
      "<strong>About The Author:</strong> <a href='https://www.incluu.us/author/drdede/' target='_blank' rel='noopener noreferrer'>Dr. Dédé Tetsubayashi</a> (Deh-deh Teh-tsu-bye-ya-she) expertise is DEI + product + business value and integrating them into a team and organization's best practices. She is a member of the Equity Army run by Annie Jean-Baptiste, a group focused on educating organizations on Product Inclusion.",
    ],
  },
  {
    id: 12,
    title: "What is Liberatory Design?",
    description: "An introduction to liberatory design principles and how they can transform product development.",
    category: "Design",
    date: "April 6, 2024",
    readTime: "12 min read",
    image: "/blog/libdes-2.jpg",
    slug: "what-is-liberatory-design",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "At first, you might be thinking, what does design have to do with liberation? You might feel a tinge of discomfort come over you, and a sigh of, 'Is nothing safe from wokeness?' You'd be partially right. As our critical thought processes evolve, as binaries and ceilings become more expansive, we are forced to reckon with the pervasive, insidious nature of the oppressive, exploitative, white supremacist, capitalist, heteronormative, patriarchal structures we have all been indoctrinated into, voluntarily… and not.",
      "<a href='https://www.beytnadesign.com/liberatory-design' target='_blank' rel='noopener noreferrer'>'Liberatory Design is an evolution of the design thinking methodology. It's an approach to problem solving that helps people translate their equity values into action.'</a>",
      "<em>'Liberatory Design is an approach to addressing equity challenges and change efforts in complex systems. [It is] a riff on Stanford d.school's design thinking process to promote equity in design work. This framework was co-created by <a href='https://www.anaissie.com/liberatory-design/' target='_blank' rel='noopener noreferrer'>Tania Anaissie</a>, <a href='https://www.linkedin.com/in/victor-cary-66ab492b/' target='_blank' rel='noopener noreferrer'>Victor Cary</a>, <a href='https://www.linkedin.com/in/david-h-clifford-4033bb24/' target='_blank' rel='noopener noreferrer'>David Clifford</a>, <a href='https://www.linkedin.com/in/tom-malarkey/' target='_blank' rel='noopener noreferrer'>Tom Malarkey</a> and <a href='https://www.linkedin.com/in/susie-wise-33b4a0/' target='_blank' rel='noopener noreferrer'>Susie Wise</a> during a collaboration in 2016/17 with the <a href='https://nationalequityproject.org/' target='_blank' rel='noopener noreferrer'>National Equity Project</a> and the Stanford d.school K12 Lab.'</em>",
      "The framework adds explicit attention to issues of equity and systemic oppression that traditional design thinking often overlooks. It asks designers to examine their own positionality, to center the experiences of those most marginalized, and to design for systemic change rather than individual solutions.",
      "Implementing liberatory design requires ongoing commitment to learning, unlearning, and relearning. It's not a one-time training but a fundamental shift in how we approach the work of creating products and services.",
      "Liberatory Design is being applied in various sectors from education to technology to healthcare. Organizations are using these principles to create more equitable products, services, and experiences.",
      "<strong>About The Author:</strong> <a href='https://www.incluu.us/author/drdede/' target='_blank' rel='noopener noreferrer'>Dr. Dédé Tetsubayashi</a> (Deh-deh Teh-tsu-bye-ya-she) expertise is DEI + product + business value and integrating them into a team and organization's best practices.",
    ],
  },
  {
    id: 13,
    title: "The Importance of Intersectionality in Tech",
    description: "Why understanding intersecting identities is crucial for building equitable technology.",
    category: "Tech Equity",
    date: "April 5, 2024",
    readTime: "9 min read",
    image: "/blog/christina-wocintechchat-com-rmweulmcyxm-unsplash-1024x684-281-29-2.jpg",
    slug: "importance-intersectionality-in-tech",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "One of the biggest misconceptions about tech is solely exclusive to Blacks people. Think: Significance is happening that when tech companies such questioning, did you get technology isn't just a neutral tool. As little, and more to become rapidly understand to our daily lives to then discussion of safety, and the fact interest. In fact: The dangers of the trend.",
      "Intersectionality was a term made longer over time say they only surface of society space are increase multi-faceted disparities of diverse, equity, and how, and ethics. Although many big tech companies are hiring in house DEI consultants and increasing the report of diverse peoples.",
      "The term intersectionality was coined by legal scholar Kimberlé Crenshaw in 1989 to describe how different aspects of a person's social and political identities combine to create different modes of discrimination and privilege.",
      "In tech, intersectionality matters because single-axis approaches to diversity and inclusion fail to capture the experiences of people with multiple marginalized identities. A Black woman's experience in tech is not simply the sum of being Black plus being a woman.",
      "Products designed without an intersectional lens often fail users at these intersections. Voice assistants that struggle with accented English, health apps that don't account for racial differences in symptoms, hiring algorithms that discriminate against women of color.",
      "Building truly inclusive technology requires teams that understand intersectionality and processes that account for it at every stage of development.",
    ],
  },
  {
    id: 14,
    title: "Equal Pay & Caregiving: How Covid-19 Further Exacerbates Existing Inequities",
    description: "Examining how the pandemic has widened gender and racial gaps in pay and caregiving responsibilities.",
    category: "Tech Equity",
    date: "April 4, 2024",
    readTime: "8 min read",
    image: "/blog/gris-zy-1920x1080-1.jpeg",
    slug: "equal-pay-caregiving-covid19-inequities",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "International Women's day is a day on which many advocates the progress we've made in closing issues of life while the wages between men and women. Now, more than a century, this day has been observed on February in the Labor collections and also have been historically observed as a day when an employee can learn more about their rights in the workplace.",
      "The pandemic did not create gender inequity in caregiving—it exposed and accelerated it. Women, and particularly women of color, have always shouldered a disproportionate share of unpaid care work. Covid-19 made this invisible labor impossible to ignore.",
      "Women in only a matter of time grieving being dealt in the wage-gap between white men and women. Black that I haven't provided a type with Bangalore. Chicana are very progressive in their gender relations, and in that I wasn't raised to believe that feminists position within me is of 2 week my story. During this experience I decided that I had to be strong for the both.",
      "When schools and daycares closed, someone had to step back from paid work to care for children. That someone was overwhelmingly women. Mothers' labor force participation dropped to levels not seen since the 1980s.",
      "The tech industry was not immune. While some celebrated remote work as a great equalizer, the reality was that women in tech faced the same impossible choices as women everywhere—choices that will have lasting impacts on their careers and earnings.",
      "Recovery efforts must explicitly address these caregiving inequities. This means not just returning to pre-pandemic norms, but building systems that recognize and value care work and distribute it more equitably.",
    ],
  },
  {
    id: 15,
    title: "As a Black Woman, I'm Either Hyper Visible or Utterly Unseen",
    description: "Reflections on the paradox of visibility that Black women navigate in professional spaces.",
    category: "Tech Equity",
    date: "April 4, 2024",
    readTime: "7 min read",
    image: "/blog/1lhfbfkk64woxkzqw9fddig.jpeg",
    slug: "black-woman-hypervisible-or-unseen",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "I was only five years old the first time I nervously took excellent and knew little another person's experience. My father was a computer programmer and were one of the first families in the neighborhood to get a personal computer.",
      "This isn't a new phenomenon but a type with Bangalore. Chicana are very progressive in their gender relations, and in that I wasn't raised to believe that feminists position within me is of 2 week my story. During this experience I decided that I had to be strong for the both.",
      "The paradox of Black womanhood in professional spaces is that we are simultaneously hyper-visible and invisible. We are noticed for our race and gender, scrutinized for how we wear our hair or express ourselves, yet overlooked when it comes to recognition, promotion, and compensation.",
      "In tech, this paradox plays out in specific ways. Black women's ideas are often attributed to others. We are expected to represent our entire race and gender in diversity discussions while being excluded from technical conversations.",
      "The emotional labor of navigating this visibility paradox is exhausting. We must constantly calibrate our self-presentation, aware that we will be judged differently than our white and male colleagues no matter what we do.",
      "Creating truly inclusive workplaces requires understanding and addressing this paradox. It means creating systems where Black women are seen for our contributions, not just our identities, and where we can bring our full selves without penalty.",
    ],
  },
  {
    id: 16,
    title: "5 things Holding Organizations back from Transformative Change",
    description: "Common barriers that prevent organizations from achieving meaningful diversity, equity, and inclusion outcomes.",
    category: "Business Strategy",
    date: "April 3, 2024",
    readTime: "15 min read",
    image: "/blog/good_cheap_fast-1.png",
    slug: "5-things-holding-organizations-back-transformative-change",
    author: "Destiny Fox Kanno",
    content: [
      "At <a href='https://incluu.us/?utm_source=website&utm_medium=content&utm_campaign=editorial&utm_id=web.1&utm_content=links' target='_blank' rel='noopener noreferrer'>incluu, LLC</a>, we create brave spaces for life. To some, this concept may sound dreamy, ambitious, and a little '<a href='https://www.fastcompany.com/3046358/millennials-have-a-different-definition-of-diversity-and-inclusion' target='_blank' rel='noopener noreferrer'>millennial</a>', but our work in the diversity, equity, and inclusion space at the intersection of human, tech, and civil rights has continued to expose the pitfalls organizations face when they do not fully embrace and commit to their DEI initiatives.",
      "The murder of George Floyd in May 2020 and the global Black Lives Matter protests that followed forced organizations to explore the concept of breaking down barriers in their peoples, practices, and products. In doing so, many sought and are seeking more fair and inclusive practices. For help in their DEI journey, they are turning to thought partners now more than ever.",
      "Volunteers, often many of whom are members of marginalized groups, progress DEI work. From within, these volunteers build grassroots movements and shoulder the lift and rise of DEI initiatives. We are now not only seeing <a href='https://ecornell.cornell.edu/diversity-and-inclusion' target='_blank' rel='noopener noreferrer'>accredited programs</a> and <a href='https://stanfordexeced.stanford.edu/' target='_blank' rel='noopener noreferrer'>executive education courses</a> catered to this specialization, but also paid roles with devoted resources.",
      "After years of this work, we've identified five common barriers that hold organizations back from achieving the transformative change they say they want. Organizations often approach DEI with the expectation that they can have fast, cheap, and high-quality outcomes. They want to check a box.",
      "The first barrier: treating DEI as a program rather than a practice. Organizations hire a diversity officer, launch a training, and consider the work done. But DEI is not a destination—it's an ongoing commitment that must be woven into every aspect of organizational culture.",
      "Second: lack of accountability at the leadership level. DEI initiatives without executive sponsorship and accountability are doomed to fail. Leaders must be willing to be held accountable for outcomes, not just intentions.",
      "Third: centering comfort over growth. Transformative change is uncomfortable. Organizations that prioritize the comfort of dominant group members over the growth required for equity will never achieve meaningful change.",
      "Fourth: insufficient investment. Meaningful DEI work requires resources—time, money, and personnel. Organizations that expect transformation on a shoestring budget are setting themselves up for failure.",
      "Fifth: lack of systemic thinking. Individual trainings and initiatives cannot transform systems. Organizations must be willing to examine and change their policies, practices, and structures.",
      "<strong>About The Author:</strong> <a href='https://www.incluu.us/author/destiny/' target='_blank' rel='noopener noreferrer'>Destiny Fox Kanno</a> (Des-tuh-knee Foks Kah-no), going by she/her/they/them, is an Incluu Consultant whose work in Account Management, Product & Project Management, and Customer Service lends itself to various diverse projects at Incluu.",
    ],
  },
  {
    id: 17,
    title: "The Divisive Fallacy of Objective Truth",
    description: "Examining how claims of objectivity often mask and perpetuate existing power structures.",
    category: "Tech Equity",
    date: "April 2, 2024",
    readTime: "7 min read",
    image: "/blog/the_divisive_fallacy_of_objective_truth-1.png",
    slug: "divisive-fallacy-objective-truth",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "<em>[Helen] Pluckrose believes there is an objective truth! She believes in one truth that is rooted in Western, White/European ideologies of a particular scientific method which denounces any other forms of truth. Of course, this is a dangerous assumption.</em>",
      "Helen Pluckrose, the founder of the site Counterweight*, has been outspoken in her critique of Critical Social Justice Theory (CSJ). In her article, <em>What do we Mean by Critical Social Justice</em>, published earlier this year, Pluckrose attempts to explain her opposition to Critical Social Justice.",
      "Both CSJ and Liberalism, she agrees, seek to achieve social justice. Liberalism, however, assumes that the starting point of 'truth' is objective and not culturally informed. Pluckrose therefore believes that everyone can attain the same level of understanding of 'objective truth' with sufficient critical thinking skills.",
      "This assertion is not supported by Critical Social Justice theory. CSJ questions the starting point of 'truth' and asks, whose truth: what is the positionality of the person claiming said truth, and further, what are the social structures affecting the power dynamics which then inform what becomes truth?",
      "In technology, claims of objectivity are particularly seductive and particularly dangerous. Algorithms are often presented as neutral and objective, when in reality they encode the biases of their creators and the inequities present in their training data.",
      "The goal is not to abandon the pursuit of truth, but to recognize that truth-seeking is always a human endeavor, shaped by human perspectives and serving human purposes. When we acknowledge this, we can begin to ask: Whose truth? Truth in service of what?",
    ],
  },
  {
    id: 18,
    title: "We Stand in Unity with Our Asian Allies",
    description: "A statement of solidarity and commitment to supporting Asian communities facing increased violence and discrimination.",
    category: "Tech Equity",
    date: "April 1, 2024",
    readTime: "5 min read",
    image: "/blog/pexels-photo-5723322-1.jpeg",
    slug: "stand-in-unity-asian-allies",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "It has taken us some time to find the words to express our deep empathy, sympathy, and worry for Asian communities amidst the anti-Asian violence experienced by Asian people across this country. From a spa in Atlanta to a street in San Francisco to countless unreported incidents, Asian Americans have been targeted.",
      "We do not wish to merely lip service in order to connect with readers and offer what as allies we can to Asian allies. Our goal, however, as a company, is to speak our truth and commitment to doing the work.",
      "Silence as an act of a company that has profited, is complicit, and values add of allies to our Asian allies. Today, specifically, we acknowledge that the problem is far greater than anyone single incident. Anti-Asian racism has deep roots in American history.",
      "From the Chinese Exclusion Act to Japanese internment to the murder of Vincent Chin, Asian Americans have faced systemic discrimination and violence. The recent surge in anti-Asian hate crimes is not an aberration—it is a continuation.",
      "Standing in unity means more than statements. It means educating ourselves about the specific histories and experiences of different Asian communities. It means speaking up when we witness discrimination. It means supporting Asian-owned businesses and Asian-led organizations.",
      "It means examining how our own organizations may perpetuate the model minority myth and other harmful stereotypes. And it means committing to the long-term work of building solidarity across communities of color.",
    ],
  },
  {
    id: 19,
    title: "What Is Intersectionality and Why Is It Important",
    description: "An introduction to the concept of intersectionality and its relevance to equity work.",
    category: "Tech Equity",
    date: "March 17, 2024",
    readTime: "8 min read",
    image: "/blog/post1-1955x2048-2.jpg",
    slug: "what-is-intersectionality-why-important",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "It's been over three decades since legal professor, Kimberlé Crenshaw, coined the term intersectionality. The phrase was used to better define the way race and specific experiences need to be recognized.",
      "As often spoken about in the war our specific discrimination narratives, The intersectionality just a critical lens through which we can understand how different aspects of a person's identity overlap and create unique experiences of discrimination or privilege.",
      "In her groundbreaking 1989 paper, Kimberle Crenshaw pointed to the problems with considering race and gender as mutually exclusive categories. Using the example of Black women workers, Crenshaw showed how discrimination at the intersection of race and gender was invisible to existing legal frameworks.",
      "The concept has since expanded beyond its legal origins to become a fundamental framework for understanding all forms of oppression and privilege. It recognizes that we cannot understand any single axis of identity in isolation.",
      "In tech, intersectionality helps us understand why diversity initiatives focused on single dimensions often fail. Hiring more women doesn't help if those women are all white. Addressing racial bias doesn't help if it ignores how that bias manifests differently for men and women.",
      "Building truly inclusive products and organizations requires an intersectional lens—one that accounts for how multiple forms of marginalization interact and compound.",
    ],
  },
  {
    id: 20,
    title: "Racism and The Wellness Industry",
    description: "Examining how the wellness industry perpetuates racial inequities while appropriating from cultures of color.",
    category: "Tech Equity",
    date: "March 7, 2024",
    readTime: "9 min read",
    image: "/blog/tanaka-pendeke-o9gfrup1l9w-unsplash-scaled-2.jpg",
    slug: "racism-and-wellness-industry",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Ahh (imagine a slow tantric breathing style at the balance of inner: stress and rejuvenation of. the Academy Awards.), Wellness. Cue wind gong for celebrity anchoring Mantras Manifestation Motivation. Wellness products....",
      "The wellness industry has exploded into a multi-billion dollar market, promising self-care, healing, and transformation. But beneath the serene aesthetics lies a troubling pattern of cultural appropriation and racial exclusion.",
      "Wellness culture borrows heavily from Eastern religions including incorporating pieces: ancient practices that have sustained communities for generations. Like in Hinduism, a practice of certain types of yoga are just as sacred as Baptism is to Christians or Shabbat is to Jews.",
      "Meanwhile, the wellness industry remains overwhelmingly white—in its leadership, its marketing, its target customers, and the bodies deemed worthy of wellness. Communities of color face barriers to accessing wellness services while watching their cultural practices commodified.",
      "Race-based medicine and algorithm bias have real consequences for the health of people of color. The same industry that appropriates healing practices from communities of color often fails to serve those communities.",
      "True wellness must include racial justice. It must acknowledge the cultural origins of practices, ensure equitable access, and reckon with how stress from racism itself impacts health outcomes in communities of color.",
    ],
  },
  {
    id: 21,
    title: "Race Norming and Bioethics",
    description: "How race-based adjustments in medical algorithms perpetuate health disparities.",
    category: "Tech Equity",
    date: "March 7, 2024",
    readTime: "10 min read",
    image: "/blog/trnava-university-lr_mkznghuu-unsplash-scaled-2.jpg",
    slug: "race-norming-and-bioethics",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Race norming — also called 'race corrections', 'ethnic adjustments', and 'race adjustment' — refers to the adjustment of medical test results or diagnostic calculations based on a patient's race. But why does this still exist?",
      "Race norming has a problematic history in fields ranging from employment testing to criminal justice. In medicine, it manifests as algorithms that adjust diagnostic thresholds based on race, often resulting in Black patients receiving less aggressive treatment.",
      "Consider the eGFR, a test that estimates kidney function. For decades, this test included a race-based adjustment that classified Black patients as having better kidney function than non-Black patients with identical lab values. The result? Black patients were less likely to be diagnosed with kidney disease and referred for transplant.",
      "After years of advocacy by Black physicians and patients, major medical organizations have begun removing race from clinical algorithms. But the damage of decades of race-normed medicine persists in health disparities.",
      "The bioethics questions are profound. Race is a social construct, not a biological one. Using it as a variable in medical algorithms reifies the false notion of biological racial difference while obscuring the real causes of health disparities: racism, discrimination, and unequal access to care.",
      "As AI becomes more prevalent in medicine, we must be vigilant that these tools do not perpetuate race-based medicine under the guise of objectivity. Algorithms trained on historically biased data will reproduce those biases unless intentionally designed otherwise.",
    ],
  },
  {
    id: 22,
    title: "Black Excellence and the Low Expectations of White Supremacy",
    description: "Challenging the narrative of Black excellence and examining its relationship to systemic racism.",
    category: "Tech Equity",
    date: "March 6, 2024",
    readTime: "8 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "black-excellence-low-expectations-white-supremacy",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Black people are plagued by Imposter Syndrome, undermining their own competency and self-worth. Believing that other folks observe that we can do better, we push ourselves harder.",
      "In the wake of George Floyd's murder, companies expressed a hunger to do better, requiring a review of how those actions relate to anti-racism systems across businesses. They revealed that while diverse employees are often the preferred option, they are constantly under scrutiny.",
      "The pressure to perform perfectly—to represent the entire race with every action—is a burden unique to those operating in spaces where they are underrepresented. Black professionals often feel they cannot simply be good at their jobs; they must be exceptional.",
      "This demand for excellence is not a sign of respect—it is a symptom of white supremacy. It says that Black people must work twice as hard for half the recognition, that our presence in professional spaces is conditional on outperforming our white peers.",
      "Meanwhile, mediocre performance from white employees is often accepted, excused, or attributed to external factors. The same grace is rarely extended to Black employees, whose failures are seen as confirmation of racial stereotypes.",
      "Dismantling this dynamic requires creating environments where Black employees can be average, can make mistakes, can learn and grow—where our humanity is not contingent on our exceptionalism.",
    ],
  },
  {
    id: 23,
    title: "The Spirit of Juneteenth is Acknowledgement",
    description: "Reflecting on the meaning of Juneteenth and the ongoing struggle for Black liberation.",
    category: "Tech Equity",
    date: "March 3, 2024",
    readTime: "6 min read",
    image: "/blog/the-spirit-of-juneteenth-1.png",
    slug: "spirit-of-juneteenth-acknowledgement",
    author: "Destiny Fox Kanno",
    content: [
      "<strong>Recognizing <a href='https://www.woojr.com/learn-about-juneteenth-for-kids-a-celebration-of-freedom/' target='_blank' rel='noopener noreferrer'>Juneteenth</a> as a National Holiday is not a solution to ending racism. It's a bandaid, a temporary fix to a wound at which we have given only a cursory triage.</strong>",
      "<strong>Establishing Juneteenth as a federal holiday is an acknowledgement of slavery, which as an institution, has morphed appearances and changed tactics often in order to remain viable in today's society. Juneteenth recognizes the subjugation of people which continued long after it was supposed to have ended.</strong>",
      "<strong>Acknowledgement is only the beginning.</strong>",
      "<a href='https://www.teenvogue.com/story/white-supremacy-is-the-problem' target='_blank' rel='noopener noreferrer'><strong>The Institution of White Supremacy</strong></a> continues to marginalize anyone different. Instead of transformative changes like <a href='https://www.brookings.edu/blog/up-front/2020/12/08/the-black-white-wealth-gap-left-black-households-more-vulnerable/' target='_blank' rel='noopener noreferrer'>eradicating systems of inequal wealth distribution</a>, we get a holiday.",
      "True acknowledgement requires reckoning. It requires examining how our institutions, our technologies, and our practices perpetuate the legacy of slavery and subsequent systems of oppression.",
      "This Juneteenth and every day, let us commit to acknowledgement that leads to action. Let us build technologies that advance Black liberation rather than perpetuating oppression.",
    ],
  },
  {
    id: 24,
    title: "60 Minutes and (En)Coded Bias",
    description: "Reflecting on the 60 Minutes segment about algorithmic bias and Joy Buolamwini's groundbreaking research.",
    category: "Tech Equity",
    date: "March 3, 2024",
    readTime: "7 min read",
    image: "/blog/joy_buolamwini_-_wikimania_2018_01-1-2.jpg",
    slug: "60-minutes-encoded-bias",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Just Reactions of pattern building with the joy: you'd have you spend time. Spend effort, that when you see a First Generation College student majoring in computer science, and what's one of the premier institutions going to see today.",
      "Joy's segment on 60 minutes & Facial recognition technology, referring to a December 2019 National Institute of Standards and Technology (NIST) facial Recognition Vendor Test or 'FRVT' where among the 189 algorithms submitted, the study was based, and conducted by AI research pioneers and Black women, Joy Buolamwini, Dr. Timnit Gebru and others.",
      "The 60 Minutes piece brought mainstream attention to what researchers have been documenting for years: facial recognition technology fails disproportionately on darker-skinned faces, particularly darker-skinned women.",
      "Dr. Buolamwini's work, starting with her experience of facial recognition systems failing to detect her face unless she wore a white mask, has been instrumental in exposing these disparities. Her Gender Shades research provided the empirical evidence that forced the industry to confront its biases.",
      "The consequences of biased facial recognition are not abstract. Real people are being misidentified, wrongfully arrested, and denied services because these systems were not designed with them in mind.",
      "The 60 Minutes segment was an important step in public awareness, but awareness alone is not enough. We need policy action, corporate accountability, and continued pressure to ensure that AI systems work equitably for everyone.",
    ],
  },
  {
    id: 25,
    title: "From Invisibility to Radical Empathy",
    description: "A journey from feeling unseen to cultivating deep understanding across difference.",
    category: "Tech Equity",
    date: "March 3, 2024",
    readTime: "8 min read",
    image: "/blog/0ha5_gjflj6n_okrx.jpeg",
    slug: "from-invisibility-to-radical-empathy",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "I am passionate about my work as a Product Inclusion Specialist, a profession where I build products that work for everyone, applying equitable or merely transactional profit practices, because growth in the money of equal inclusion not company progress.",
      "My work is not an accident—it is the culmination of a lifetime of experiences navigating systems that were not designed for people like me. From being the only Black student in advanced classes to being one of few Black women in tech.",
      "The journey from invisibility to empathy began with seeing myself reflected in others' struggles. Understanding that my experiences of marginalization connected me to others facing different but related forms of exclusion.",
      "Radical empathy goes beyond sympathy or even standard empathy. It requires us to decenter ourselves, to sit with discomfort, to truly listen to experiences different from our own without defensiveness or the urge to fix.",
      "In tech, radical empathy means designing with, not for. It means including affected communities throughout the development process, not just as an afterthought. It means being willing to fundamentally change course when we learn our products cause harm.",
      "My work with Incluu and with our partners is rooted in this radical empathy—a belief that we can build technologies that advance human flourishing for everyone, not just those who have historically been centered.",
    ],
  },
]

export function getBlogPost(slug: string): BlogPost | undefined {
  return blogPosts.find((post) => post.slug === slug)
}

export function getPostBySlug(slug: string): BlogPost | undefined {
  return blogPosts.find((post) => post.slug === slug)
}

export function getAllPostSlugs(): string[] {
  return blogPosts.map((post) => post.slug)
}

export function getAllCategories(): string[] {
  const categories = blogPosts.map((post) => post.category)
  return [...new Set(categories)]
}

export function getRelatedPosts(currentSlug: string, limit: number = 3): BlogPost[] {
  const currentPost = getBlogPost(currentSlug)
  if (!currentPost) return blogPosts.slice(0, limit)

  return blogPosts
    .filter((post) => post.slug !== currentSlug && post.category === currentPost.category)
    .slice(0, limit)
}
