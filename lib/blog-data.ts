export interface BlogPost {
  id: number
  title: string
  description: string
  category: string
  date: string
  readTime: string
  image: string
  slug: string
  author: string
  content: string[]
}

// Combined blog posts - Original 7 articles first (newest to oldest), then 18 Squarespace imports
export const blogPosts: BlogPost[] = [
  // ============================================
  // ORIGINAL 7 ARTICLES (January 2026 - November 2025)
  // ============================================
  {
    id: 1,
    title: "The EU AI Act: What Leaders Need to Know in 2026",
    description: "A comprehensive guide to the EU AI Act requirements and how organizations can prepare for compliance.",
    category: "AI Governance",
    date: "January 15, 2026",
    readTime: "8 min read",
    image: "/modern-corporate-office-with-diverse-team-working-on-ai-governance.jpg",
    slug: "eu-ai-act-guide-2026",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The EU AI Act represents the most comprehensive AI regulation globally, and 2026 marks a critical year for compliance. Organizations deploying AI systems in the European Union must understand their obligations and take proactive steps to ensure compliance. This landmark legislation will fundamentally reshape how businesses develop, deploy, and maintain artificial intelligence systems across all sectors.",
      "As someone who has spent over two decades at the intersection of technology and policy, I've watched this regulation evolve from early proposals to the comprehensive framework we see today. The Act didn't emerge in a vacuum—it's the culmination of years of growing concern about AI's impact on fundamental rights, safety, and democratic values.",
      "Understanding the Risk-Based Approach: The Act categorizes AI systems into four distinct risk levels, each with different compliance obligations. Unacceptable risk systems are outright banned—these include social scoring systems, real-time biometric identification in public spaces (with limited exceptions), and AI that manipulates human behavior to circumvent free will. High-risk systems face the most stringent requirements and include AI used in critical infrastructure, education, employment, essential services, law enforcement, and border management.",
      "Limited risk systems, such as chatbots and deepfakes, must meet transparency requirements—users must be informed they're interacting with AI. Minimal risk systems, which constitute the vast majority of AI applications, face no specific regulatory requirements under the Act, though general principles of responsible AI development still apply.",
      "Key Compliance Requirements for High-Risk Systems: Organizations deploying high-risk AI must implement comprehensive risk management systems that identify, analyze, evaluate, and mitigate risks throughout the AI lifecycle. This isn't a one-time assessment—it requires ongoing monitoring and updates as the system evolves and new risks emerge.",
      "The organizations that thrive under the EU AI Act will be those that view compliance not as a burden but as an opportunity to build trust, differentiate from competitors, and create AI systems that genuinely serve human flourishing. The regulatory landscape is shifting—the question is whether your organization will lead or follow.",
    ],
  },
  {
    id: 2,
    title: "Disability as Innovation Driver: The Business Case",
    description: "How inclusive design and accessibility-first thinking can unlock new markets and drive competitive advantage.",
    category: "Tech Equity",
    date: "January 8, 2026",
    readTime: "6 min read",
    image: "/diverse-team-collaborating-on-inclusive-technology.jpg",
    slug: "disability-innovation-driver",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "When we design for the margins, we create solutions that benefit everyone. This isn't just a moral imperative—it's a business strategy that has proven to unlock significant value for organizations willing to embrace inclusive design. Throughout my career, I've seen firsthand how accessibility-first thinking transforms not just products, but entire organizational cultures.",
      "The numbers tell a compelling story. According to the World Health Organization, 1.3 billion people globally live with some form of disability—that's 16% of the world's population. This community represents $13 trillion in annual disposable income. Add aging populations (by 2050, one in six people will be over 65), temporary disabilities, and situational impairments, and the addressable market for accessible products expands dramatically.",
      "The Curb Cut Effect: Innovation That Benefits Everyone: The curb cut effect, named after the sloped sidewalk cuts originally designed for wheelchair users, illustrates how solutions designed for specific populations often benefit everyone. Parents with strollers, travelers with luggage, delivery workers with hand trucks—all benefit from curb cuts. The same principle applies throughout technology.",
      "More fundamentally, accessibility-first design creates better products for everyone. The discipline of designing for extreme users forces clearer thinking, simpler interfaces, and more robust systems. It's a competitive advantage hiding in plain sight—one that most of your competitors are still ignoring.",
    ],
  },
  {
    id: 3,
    title: "Building Ethical AI Systems: A Framework for Success",
    description: "Practical steps for implementing ethical AI governance that protects your organization and serves all users.",
    category: "AI Governance",
    date: "December 20, 2025",
    readTime: "10 min read",
    image: "/executive-team-reviewing-compliance-dashboard.jpg",
    slug: "ethical-ai-framework",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Ethical AI isn't just about avoiding harm—it's about building systems that actively promote fairness, transparency, and human flourishing. This requires a comprehensive framework that addresses every stage of the AI lifecycle, from initial conception through deployment, monitoring, and eventual decommissioning.",
      "Over my years advising Fortune 500 companies on AI governance, I've developed a framework built on four pillars that has proven effective across industries and use cases. These pillars—Lead with Curiosity, Be Accountable, Solve for One, Extend to Many, and Take Action—provide both philosophical grounding and practical guidance.",
      "Pillar 1: Lead with Curiosity: The first pillar challenges us to examine our assumptions and actively seek out blind spots. AI systems are built by humans, trained on human-generated data, and reflect human decisions at every turn. Without intentional curiosity, we inevitably encode our biases and limitations into these systems.",
      "The organizations that master ethical AI development will build trust with customers, attract top talent, navigate regulatory requirements more easily, and create AI systems that genuinely serve human flourishing. The framework is clear—now it's time to put it into practice.",
    ],
  },
  {
    id: 4,
    title: "The ROI of Accessible Technology",
    description: "Quantifying the business value of accessibility investments and inclusive design practices.",
    category: "Business Impact",
    date: "December 12, 2025",
    readTime: "7 min read",
    image: "/diverse-team-celebrating-inclusive-product-launch.jpg",
    slug: "roi-accessible-technology",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Accessibility investments deliver measurable returns across multiple dimensions: risk mitigation, market expansion, operational efficiency, brand value, and talent attraction. Understanding and quantifying these returns is essential for building the business case for inclusive design and securing the resources needed for meaningful accessibility improvements.",
      "For too long, accessibility has been framed primarily as a compliance obligation or charitable gesture. While legal compliance and moral considerations are important, they rarely drive sustained organizational commitment. By quantifying the business value of accessibility, we can shift the conversation from 'should we invest in accessibility?' to 'how much should we invest to maximize returns?'",
      "Risk Mitigation: The Cost of Inaction: The legal landscape around accessibility has transformed dramatically. ADA-related lawsuits increased 320% between 2018 and 2025, with digital accessibility claims now comprising the majority of cases.",
      "Market Expansion: The Disability Market Advantage: The disability market represents $13 trillion in annual disposable income globally. In the US alone, people with disabilities control over $490 billion in disposable income.",
    ],
  },
  {
    id: 5,
    title: "Algorithmic Bias: Detection and Prevention Strategies",
    description: "Understanding how bias enters AI systems and practical approaches to identify and mitigate it.",
    category: "AI Governance",
    date: "December 5, 2025",
    readTime: "9 min read",
    image: "/diverse-tech-team-collaborating-in-modern-office.jpg",
    slug: "algorithmic-bias-prevention",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Algorithmic bias represents one of the most significant challenges facing AI development today. When machine learning systems encode and amplify existing societal biases, the consequences can be severe—from discriminatory hiring decisions to biased criminal sentencing recommendations to healthcare disparities that cost lives.",
      "Understanding how bias enters AI systems is the first step toward addressing it. Bias can creep in at every stage of the AI development lifecycle: during problem formulation, data collection, feature selection, model training, evaluation, and deployment. Each stage presents unique risks and requires specific mitigation strategies.",
      "Data-Level Interventions: Perhaps the most common source of algorithmic bias is biased training data. Historical data reflects historical discrimination—if your hiring algorithm is trained on past hiring decisions, it will learn to replicate any bias present in those decisions.",
      "The goal isn't to create perfectly unbiased systems—that's likely impossible. The goal is to build systems with understood limitations, appropriate safeguards, and meaningful human oversight. This requires ongoing vigilance, regular auditing, and a commitment to continuous improvement.",
    ],
  },
  {
    id: 6,
    title: "Rest as Resistance: The Wellness Imperative for Leaders",
    description: "Why executive wellness and intentional rest are essential for sustainable leadership and innovation.",
    category: "Wellness",
    date: "November 28, 2025",
    readTime: "5 min read",
    image: "/diverse-executives-in-meditation-session.jpg",
    slug: "rest-as-resistance-leaders",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "In a culture that glorifies hustle and equates busyness with importance, rest becomes a radical act. For leaders—especially those from marginalized communities who face additional pressures to prove their worth—intentional rest is not just self-care; it's a form of resistance against systems designed to extract maximum productivity at the expense of human flourishing.",
      "The research is clear: chronic stress and sleep deprivation impair cognitive function, emotional regulation, and decision-making. Leaders operating under these conditions make poorer decisions, treat their teams worse, and are more likely to burn out. Yet our culture continues to celebrate leaders who sacrifice sleep, skip vacations, and wear their exhaustion as a badge of honor.",
      "For BIPOC leaders and those from other marginalized groups, the pressure to perform is amplified. We often feel we must work twice as hard to receive half the recognition. We navigate microaggressions, code-switching, and the weight of being 'the only one' in many rooms. This additional cognitive and emotional labor makes rest even more essential—and often even harder to take.",
      "Rest as resistance means reclaiming your time and energy from systems that would consume them entirely. It means recognizing that your value is not determined by your productivity. It means modeling sustainable leadership for your teams and refusing to perpetuate cultures of overwork.",
    ],
  },
  {
    id: 7,
    title: "Navigating AI Governance: A C-Suite Perspective",
    description: "Strategic insights for executive leaders on building responsible AI governance frameworks.",
    category: "AI Governance",
    date: "November 20, 2025",
    readTime: "8 min read",
    image: "/professional-business-meeting-discussing-ai-govern.jpg",
    slug: "ai-governance-c-suite-perspective",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "AI governance has moved from a technical concern to a boardroom priority. As AI systems become increasingly central to business operations and customer experiences, executive leaders must develop the strategic competency to oversee AI responsibly. This requires understanding both the opportunities and the risks that AI presents.",
      "The business case for AI governance is compelling. Organizations with mature AI governance frameworks experience fewer regulatory penalties, stronger customer trust, reduced legal exposure, and better AI performance. They're also better positioned to attract AI talent, who increasingly want to work for organizations committed to responsible AI development.",
      "Building Governance Competency at the Executive Level: Effective AI governance starts with board-level understanding of AI capabilities and limitations. This doesn't mean every executive needs to become a data scientist—but they do need enough AI literacy to ask the right questions and evaluate the answers.",
      "The organizations that will thrive in an AI-driven future are those that treat governance not as a constraint but as a competitive advantage. By building robust governance frameworks now, you position your organization for sustainable AI success.",
    ],
  },

  // ============================================
  // 18 SQUARESPACE BLOG IMPORTS (April 2024 - March 2024)
  // ============================================
  {
    id: 8,
    title: "Ethical AI and Smart Lock Systems",
    description: "Examining the ethical implications of smart lock systems that use facial recognition technology and their impact on marginalized communities.",
    category: "AI Governance",
    date: "April 19, 2024",
    readTime: "6 min read",
    image: "/blog/christina-wocintechchat-com-rmweulmcyxm-unsplash-1024x684-281-29.jpg",
    slug: "ethical-ai-and-smart-lock-systems",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "I recently sat down with a group to discuss the pros and cons of emerging technologies from my perspective as both anthropologist and ethical technologist; specifically, smart lock systems. For those who may be unfamiliar with smart lock systems, they are a relatively new technological advancement that uses image and facial recognition software to enable users entry to businesses and residences thereby eliminating physical keys; this technology is believed to increase safety and ease of accessibility.",
      "No more misplaced and lost keys, costly locksmith services, and the ease of allowing temporary and/or limited access to vendors, guests, and service providers. These are the pros and admittedly, they are cost-efficient, time-saving, and an added convenience for some – perhaps, many.",
      "There is a misconception that AI is godlike, infallible even; but AI is a product of wholly fallible human design. Coded into the complex algorithms are the same biases we deal with in our day to day human experiences. Laypersons are more apt to buy into a science they don't fully understand and this leaves an already over-policed, vulnerable faction of the population at a heightened risk of unprecedented, unmitigated harm.",
      "Within the past month, a Black sixteen year old was seriously wounded after being shot by a White homeowner for ringing his doorbell in error. It is not only reasonable to suspect, but to assert the homeowner reacted with such heightened hostility towards the error and minor inconvenience due to his own preconceived notions about race.",
      "What, then, do we do when there is a discrepancy between the human-coded smartlock technology algorithms and the humans seeking safe, equitable access? The answer is complex, but begins with intentional, inclusive design that centers the most marginalized users from the very beginning of the development process.",
    ],
  },
  {
    id: 9,
    title: "The Pitfalls of Adversarial Clothing",
    description: "An exploration of adversarial clothing designed to confuse facial recognition systems and the unintended consequences for marginalized communities.",
    category: "Tech Equity",
    date: "April 18, 2024",
    readTime: "8 min read",
    image: "/blog/adversarial-clothing.png",
    slug: "pitfalls-of-adversarial-clothing",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "When I present on panels about equitable and inclusive design, there are two areas I emphasize; as both a social scientist and tech ethicist, these are the areas where we, as humans have the greatest opportunity to bring about transformative change.",
      "The first and most fundamental tool we have within our arsenal is the call-in. The call-in is the seed from which the best accessible, equitable, and inclusive products and processes take shape. Who am I designing this for? Who am I designing it with? If they are not one and the same, we must go back and begin again.",
      "The second is more of a guiding principle, 'Design for one, extend to many.' This principle from my friend and mentor, Kat Holmes is another essential tool in designing accessibly and equitably.",
      "I've written about hyper-reliance on facial recognition technology and the added layer of harm it causes for the oft-misidentified BIPOC and LGBTQ+ communities, so when adversarial clothing brands started to emerge, my interests were piqued and as it turns out, I wasn't alone.",
      "I recently sat with a small group to discuss the rapid growth of facial recognition technologies and more specifically the harms inevitably levied upon us by the designers, the consumers, and even so-called adversaries of these technologies. With a focus on accessibility, equity, and harm mitigation what remains clear is that the solution must center those most impacted.",
    ],
  },
  {
    id: 10,
    title: "Facial Recognition and Racial Bias",
    description: "Examining how facial recognition technology disproportionately harms BIPOC communities and the urgent need for regulation.",
    category: "AI Governance",
    date: "April 18, 2024",
    readTime: "7 min read",
    image: "/blog/amol-tyagi-0juktkotkpu-unsplash-1638x2048.jpg",
    slug: "facial-recognition-and-racial-bias",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "It is estimated that almost half of American adults – over 117 million people, as of 2016 – have photos within a facial recognition network used by law enforcement. This participation occurs without consent, or even awareness, and is bolstered by a lack of legislative oversight. More disturbingly, however, the current implementation of these technologies involves significant racial bias, particularly against Black Americans.",
      "In as many years, 3 Black men have had their lives upended by wrongful arrests. Robert Williams, Michael Oliver, and Nijeer Parks were misidentified by facial recognition software, arrested, and held under suspicion of crimes ranging from petty theft to assault of a police officer.",
      "For Parks, who was accused of the more serious crimes of assault and eluding the police, the fight to clear his name went on for the better part of a year. Before his case was thrown out of court, and his name cleared, Parks would go on to spend 10 days in jail, all due to hyper-reliance on technology.",
      "Despite widely published research findings detailing the issues of misidentification of darker skinned faces by facial recognition technologies, law enforcement's hyper-reliance remains. For BIPOC, and most notably, dark-skinned Black women (for whom misidentification occurs as often as 33% of the time compared to that of white men) this adds an added layer of concern.",
      "'Automated systems are not inherently neutral. They reflect the priorities, preferences, and prejudices—the coded gaze—of those who have the power to mold artificial intelligence.' - Gendershades.org",
    ],
  },
  {
    id: 11,
    title: "Digital Blackface: Are you complicit?",
    description: "Understanding digital blackface and how the use of Black GIFs and memes perpetuates harmful stereotypes in online spaces.",
    category: "Tech Equity",
    date: "April 7, 2024",
    readTime: "6 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "digital-blackface-are-you-complicit",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "'Digital blackface' is used to describe various types of minstrel performance that become available in cyberspace. Blackface minstrelsy is a theatrical tradition dating back to the early 19th century, in which performers 'blacken' themselves up with costume and behaviors to act as black caricatures. The performances put society's most racist sensibilities on display and in turn fed them back to audiences to intensify these feelings and disperse them across culture. - Lauren Michele Jackson, Teen Vogue",
      "For those of us at the forefront of the fight for liberation, the obstacles seem endless. It would appear that every facet of our daily existence and interactions are marred by pervasive influence of white supremacy–or rather, 'white supremacist delusion' as Sonya Renee Taylor has coined it.",
      "A third of your day, everyday, is either an opportunity for harm or harm reduction and liberation. We've all seen it so much that in many ways, we are desensitized, while some others become hyperaware and/or hypervigilant.",
      "There's a Facebook or Twitter thread or maybe even group chat amongst peers and someone drops a GIF or a meme and the group is divided. Perhaps, it's RHOA (Real Housewives of Atlanta) reality star Nene Leakes, or a lesser known, likely unsuspecting, usually Black or Brown person whose image has been co-opted and turned into a meme.",
      "As harmless and even humorous as this seems, these are real people and we must ask ourselves, 'Why them?' Why not snap a selfie to express your emotions, or take a little extra time to search for an image closer to your own likeness?",
    ],
  },
  {
    id: 12,
    title: "What is Liberatory Design?",
    description: "An introduction to liberatory design principles and how they can transform product development for equity.",
    category: "Tech Equity",
    date: "April 6, 2024",
    readTime: "6 min read",
    image: "/blog/good_cheap_fast-2.png",
    slug: "what-is-liberatory-design",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Liberatory Design is a creative problem-solving approach that centers equity and aims to disrupt systems of oppression through intentional design choices. It draws from equity-centered design, design thinking, and critical race theory to create products, services, and systems that actively work toward liberation rather than perpetuating harm.",
      "The framework challenges designers to examine their own positionality and biases, center the voices of those most impacted by the problem being solved, and consider the systemic implications of their design decisions.",
      "Key principles of Liberatory Design include: Notice and reflect on your own assumptions; Learn from the lived experiences of those most impacted; Find opportunities to disrupt systems of oppression; Build power with and for communities.",
      "In practice, this means moving beyond user-centered design to community-centered design, where affected communities are not just consulted but are active partners in the design process. It means asking not just 'Does this work?' but 'Who does this serve?' and 'Who might this harm?'",
      "Liberatory Design offers a path toward creating technology that genuinely serves human flourishing and actively works to dismantle systems of oppression.",
    ],
  },
  {
    id: 13,
    title: "The Importance of Intersectionality in Tech",
    description: "Exploring why intersectional analysis is essential for creating truly inclusive technology products.",
    category: "Tech Equity",
    date: "April 5, 2024",
    readTime: "7 min read",
    image: "/blog/ariel-sion-i7v-btpnktg-unsplash-2048x1365.jpg",
    slug: "importance-intersectionality-in-tech",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Intersectionality, coined by legal scholar Kimberlé Crenshaw, describes how different aspects of a person's identity—race, gender, class, disability, sexuality—combine to create unique experiences of discrimination and privilege. In technology, applying an intersectional lens is essential for creating products that truly serve all users.",
      "A Black disabled woman, for example, experiences technology differently than a white disabled man or a Black able-bodied woman. Her needs and challenges exist at the intersection of multiple identities, and solutions that address only one dimension will fail her.",
      "Tech companies often approach diversity in silos—separate initiatives for women, for BIPOC employees, for people with disabilities. But this siloed approach misses those who exist at the intersections and often results in solutions that serve only the most privileged members of each group.",
      "Applying intersectionality in tech means diverse teams that reflect multiple intersecting identities; user research that specifically seeks out participants at various intersections; product testing that examines how features perform for users with multiple marginalized identities; and metrics that can be disaggregated to reveal disparities hidden in aggregate data.",
      "When we design with intersectionality in mind, we create more robust, more equitable products that better serve the full diversity of human experience.",
    ],
  },
  {
    id: 14,
    title: "Equal Pay & Caregiving: How Covid19 Further Exacerbates Existing Inequities",
    description: "Analyzing how the pandemic has widened the wage gap for women of color and increased caregiving burdens disproportionately.",
    category: "Tech Equity",
    date: "April 4, 2024",
    readTime: "7 min read",
    image: "/blog/0ha5_gjflj6n_okrx.jpeg",
    slug: "equal-pay-caregiving-covid19-inequities",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "International Women's day is a day in which many celebrate the progress we're making towards equal pay and fair wages between men and women. Over more than a century, this day has been observed in February on the Julian calendar and March on the Gregorian calendar.",
      "What is encoded in the language—as is often the case—is that International Women's Day is actually only a marker of the progress being made to bridge the wage gap between white men and white women.",
      "Black women currently observe equal pay day in August—August 3rd, this year, and it has yet to become cause for celebration; we have had to work approximately 8 months into the new year just to earn the same amount of pay that white (Non-Hispanic) men earned last year.",
      "'Black women's gender pay gap has only closed three cents in 30 years, according to the National Women's Law Center. This disparity adds up to a typical loss of $24,110 dollars a year, totaling about $900,000 over a 40-year career.' - Fortune",
      "BIPOC women disproportionately comprise roles in service industries placing them in a precarious position as COVID-19 ravaged the country. Not only is the exposure risk for COVID-19 greater for essential workers, but untreated comorbidities pose an added risk.",
    ],
  },
  {
    id: 15,
    title: "As a Black Woman, I'm Either Hyper Visible or Utterly Unseen",
    description: "Reflecting on the dual experience of hypervisibility and invisibility that Black women face in professional and public spaces.",
    category: "Tech Equity",
    date: "April 4, 2024",
    readTime: "5 min read",
    image: "/blog/1lhfbfkk64woxkzqw9fddig.jpeg",
    slug: "black-woman-hypervisible-or-unseen",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "As a Black woman navigating professional spaces, I exist in a constant state of paradox. I am simultaneously too visible and completely invisible. My presence is noted, scrutinized, and policed, yet my contributions, expertise, and humanity are often overlooked entirely.",
      "This duality is exhausting. In meetings, my ideas may be dismissed only to be celebrated when repeated by a colleague with more privilege. My appearance is commented on in ways that would never be directed at my white counterparts. I am asked to speak for all Black women while being told my individual experiences are not representative.",
      "Technology has not solved this problem—in many ways, it has amplified it. Facial recognition systems struggle to see me accurately, yet surveillance systems track my every move. AI systems trained on biased data perpetuate the same patterns of erasure and over-policing that I experience in physical spaces.",
      "The path forward requires intentional design that centers the experiences of those who have been historically marginalized. It requires diverse teams who can identify blind spots. It requires accountability mechanisms that catch bias before it causes harm.",
      "Most importantly, it requires listening to Black women and other marginalized groups—not as research subjects or token voices, but as experts in our own experiences and as essential partners in building technology that works for everyone.",
    ],
  },
  {
    id: 16,
    title: "5 things Holding Organizations back from Transformative Change",
    description: "Identifying the key obstacles that prevent organizations from achieving meaningful progress on diversity, equity, and inclusion initiatives.",
    category: "Business Impact",
    date: "April 3, 2024",
    readTime: "9 min read",
    image: "/blog/good_cheap_fast-2.png",
    slug: "5-things-holding-organizations-back-transformative-change",
    author: "Destiny Fox Kanno",
    content: [
      "At incluu, LLC, we create brave spaces for life. To some, this concept may sound dreamy, ambitious, and a little 'millennial', but our work in the diversity, equity, and inclusion space at the intersection of human, tech, and civil rights has continued to expose the pitfalls organizations face when they do not fully embrace and commit to their DEI initiatives.",
      "The murder of George Floyd in May 2020 and the global Black Lives Matter protests that followed forced organizations to explore the concept of breaking down barriers in their peoples, practices, and products.",
      "From that experience, we've learned that an organization's failure to achieve and reach its full potential for real, sustainable transformative change stems from five factors:",
      "1. Inability to see DEI work as mission-critical for the organization's ecosystem; 2. Lack of executive sponsorship and accountability; 3. Insufficient resources and funding; 4. Treating DEI as a checkbox rather than ongoing practice; 5. Failure to center the voices of those most impacted.",
    ],
  },
  {
    id: 17,
    title: "The Divisive Fallacy of Objective Truth",
    description: "Challenging the notion of objective truth and examining how claims to objectivity often mask systemic biases.",
    category: "Tech Equity",
    date: "April 2, 2024",
    readTime: "6 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "divisive-fallacy-objective-truth",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The claim to objectivity is often wielded as a weapon to silence marginalized voices and dismiss lived experiences. When someone asserts that their perspective is 'objective' or 'unbiased,' they are typically revealing their own blind spots rather than demonstrating superior insight.",
      "In technology, this manifests in the belief that algorithms and data are inherently neutral. We assume that if we remove human decision-makers from the process, we will eliminate bias. But algorithms are designed by humans, trained on historical data that reflects past discrimination, and deployed in systems that often lack accountability.",
      "The pursuit of 'objectivity' in AI has led to systems that claim to be fair while systematically disadvantaging marginalized groups. Recidivism prediction algorithms that encode racial bias. Hiring tools that penalize candidates from non-traditional backgrounds. Credit scoring systems that perpetuate economic inequality.",
      "Rather than striving for an impossible objectivity, we should embrace transparency about our values and assumptions. We should build systems that are accountable to the communities they affect.",
    ],
  },
  {
    id: 18,
    title: "We Stand in Unity with Our Asian Allies",
    description: "A statement of solidarity with the Asian community in the face of rising anti-Asian hate and violence.",
    category: "Tech Equity",
    date: "April 1, 2024",
    readTime: "4 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "stand-in-unity-asian-allies",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "At incluu, we stand in unwavering solidarity with our Asian, Asian American, and Pacific Islander communities in the face of rising hate, violence, and discrimination. The surge in anti-Asian attacks during and after the COVID-19 pandemic represents a continuation of historical patterns of racism and xenophobia that we must actively resist.",
      "As advocates for equity and inclusion, we recognize that our liberation is bound together. Anti-Asian racism, anti-Black racism, and all forms of oppression are interconnected manifestations of white supremacy. We cannot achieve justice for any community while others remain under threat.",
      "We commit to educating ourselves and our communities about the history of anti-Asian discrimination in this country. We commit to amplifying Asian voices and supporting Asian-led organizations.",
      "To our Asian community members: we see you, we hear you, and we stand with you. Your safety, your dignity, and your humanity are non-negotiable. Together, we will continue to fight for a world where everyone can thrive.",
    ],
  },
  {
    id: 19,
    title: "What Is Intersectionality and Why Is It Important",
    description: "An introduction to the concept of intersectionality and its critical importance in understanding and addressing systemic inequality.",
    category: "Tech Equity",
    date: "March 7, 2024",
    readTime: "7 min read",
    image: "/blog/ariel-sion-i7v-btpnktg-unsplash-2048x1365.jpg",
    slug: "what-is-intersectionality-why-important",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Intersectionality, a term coined by legal scholar Kimberlé Crenshaw in 1989, describes how different aspects of a person's social and political identities combine to create unique modes of discrimination and privilege. It recognizes that people can experience oppression in multiple, overlapping ways.",
      "A Black woman, for example, does not experience racism and sexism separately—she experiences a unique form of discrimination that cannot be understood by examining either racism or sexism alone.",
      "Understanding intersectionality is essential for creating truly inclusive products, policies, and workplaces. When we design only for a single dimension of identity, we often fail those who exist at the intersections.",
      "Applying an intersectional lens requires humility, ongoing learning, and genuine partnership with affected communities. It means recognizing that no single person or team can anticipate all the ways a product might fail marginalized users.",
    ],
  },
  {
    id: 20,
    title: "Racism and The Wellness Industry",
    description: "Examining how racism manifests in the wellness industry and the barriers to care faced by BIPOC communities.",
    category: "Wellness",
    date: "March 6, 2024",
    readTime: "6 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "racism-and-wellness-industry",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "The wellness industry, often marketed as a path to healing and self-care, has significant blind spots when it comes to race. From yoga studios that appropriate South Asian spiritual practices while excluding South Asian bodies, to meditation apps that center white experiences, to health systems that dismiss Black women's pain, racism is woven throughout wellness spaces.",
      "For BIPOC communities, the pursuit of wellness is complicated by systemic barriers. We face higher rates of chronic stress from navigating racism daily. We are more likely to be uninsured or underinsured. We are more likely to be dismissed by healthcare providers who don't take our symptoms seriously.",
      "Creating truly inclusive wellness spaces requires centering BIPOC voices and experiences. It means hiring diverse practitioners, examining pricing structures that exclude low-income communities, and acknowledging the cultural origins of practices that have been appropriated and whitewashed.",
      "Most importantly, it means recognizing that wellness for marginalized communities cannot be separated from justice. Our healing is bound up with collective liberation.",
    ],
  },
  {
    id: 21,
    title: "Race Norming and Bioethics",
    description: "Examining the practice of race norming in medicine and its harmful implications for Black patients.",
    category: "AI Governance",
    date: "March 5, 2024",
    readTime: "8 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "race-norming-and-bioethics",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Race norming, the practice of adjusting medical test results based on a patient's race, has been embedded in healthcare for decades. These adjustments are often based on the false assumption that there are inherent biological differences between racial groups—a concept that has been thoroughly debunked by modern genetics.",
      "One prominent example is the estimated glomerular filtration rate (eGFR), a measure of kidney function that has historically been calculated differently for Black patients. The race-adjusted formula assumed that Black patients had higher muscle mass, leading to systematically higher eGFR values that made Black patients appear healthier than they actually were.",
      "The consequences have been deadly. Black patients with kidney disease have been denied referrals for transplants, excluded from clinical trials, and received delayed treatment because their race-adjusted numbers suggested they were less sick than they actually were.",
      "As AI systems are increasingly used in healthcare, we must be vigilant about how historical biases—including race norming—may be encoded into these tools.",
    ],
  },
  {
    id: 22,
    title: "Black Excellence and the Low Expectations of White Supremacy",
    description: "Examining how 'soft bigotry' and low expectations perpetuate systemic barriers for Black professionals.",
    category: "Tech Equity",
    date: "March 4, 2024",
    readTime: "7 min read",
    image: "/blog/1517500824426.jpg",
    slug: "black-excellence-low-expectations-white-supremacy",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Black people are plagued by Imposter Syndrome, questioning their own competency and self worth; 'Have I gained entry, or simply been allowed entry?' White people have deliberately set the bar low, yet maintain that BIPOC entry lowers it. – Dr. Dédé Tetsubayashi, Tech Ethicist",
      "In the wake of George Floyd's murder, corporate America pledged to do better, saying it would diversify its leadership, encourage equity and take concrete actions to root out systemic racism.",
      "Why is this when Black women currently hold more post-secondary degrees percentage-wise than White women, Latinas, Asian/Pacific Islanders and Indigenous Peoples? It is likely due to what is known as 'soft bigotry'.",
      "This approach is predicated on the widely held racist beliefs of White people, that Black people—to varying degrees based on skin tone—will inevitably underperform, thus lowering the bar.",
      "Tokenism comes with a host of complexities, one of which is Imposter Syndrome. Many 'high performing' Blacks are plagued by Imposter Syndrome, questioning their own competency and self worth.",
    ],
  },
  {
    id: 23,
    title: "The spirit of Juneteenth is acknowledgement",
    description: "Reflecting on the meaning of Juneteenth and the ongoing struggle for Black liberation and recognition.",
    category: "Tech Equity",
    date: "March 3, 2024",
    readTime: "5 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "spirit-of-juneteenth-acknowledgement",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Juneteenth, commemorating the day in 1865 when enslaved people in Texas finally learned of their freedom—more than two years after the Emancipation Proclamation—carries a profound message about acknowledgement and the gap between proclamation and reality.",
      "The delayed news of freedom to those in Texas was not accidental. Enslavers deliberately withheld information to continue extracting labor from people they knew were legally free. This pattern of delayed justice, of rights recognized in principle but denied in practice, continues to this day.",
      "As we celebrate Juneteenth's federal recognition as a holiday, we must also acknowledge how much work remains. The wealth gap between Black and white Americans has barely changed since the Civil Rights era.",
      "The spirit of Juneteenth calls us to close the gap between our stated values and our lived reality. It challenges us to ensure that the freedoms we proclaim are actually experienced by all.",
    ],
  },
  {
    id: 24,
    title: "60 Minutes and (En)Coded Bias",
    description: "Examining how Black women researchers are erased from narratives about the AI bias research they pioneered.",
    category: "AI Governance",
    date: "March 2, 2024",
    readTime: "7 min read",
    image: "/blog/blog-post-image-template.png",
    slug: "60-minutes-encoded-bias",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "Gut Reaction: Droplets of water building until the cup overflows. You spend time. Spend effort. And when you see a final product, without your name— without your history— you wonder if you're the one who's crazy.",
      "Recently, CBS's 60-minutes aired a segment on racial bias in facial recognition technology, referring to a December 2019 National Institute of Standards and Technology (NIST) study as a 'landmark study' while failing to mention the groundbreaking research on which the NIST study was based, and conducted by AI-research pioneers and Black women, Joy Buolamwini, Dr. Timnit Gebru and Inioluwa Deborah Raji.",
      "Ms. Buolamwini, who spent hours prepping the 60-minutes team, was summarily not given credit for her work, nor was she acknowledged as the one who made the work groundbreaking; thus erasing her from the narration while her work and knowledge were credited to what she refers to as 'Pale Males.'",
      "Misogynoir is the racism, hatred, and prejudice aimed particularly at Black women. So, imagine my surprise when, upon sharing Ms. Buolamwini's post with my audience on LinkedIn, the very content describing this egregious act went missing on the site.",
    ],
  },
  {
    id: 25,
    title: "From Invisibility to Radical Empathy",
    description: "A personal journey from experiencing healthcare bias as a child with sickle cell to becoming an advocate for ethical technology.",
    category: "Wellness",
    date: "March 1, 2024",
    readTime: "8 min read",
    image: "/blog/0ha5_gjflj6n_okrx.jpeg",
    slug: "from-invisibility-to-radical-empathy",
    author: "Dr. Dédé Tetsubayashi",
    content: [
      "I am passionate about my work as a Product Inclusion Specialist, a profession where I build products that work for every body, regardless of ability, gender, resources, culture, race, or class. I focus on building ethical products and processes that resist exploiting customers as merely transactional profit providers.",
      "As technology has exploded around us and demonstrated capabilities beyond our imagination, we've come to believe that building machines will relieve us of our own biases and shortcomings. Machines, we believe, won't be flawed the way we are. With those beliefs in mind, we build triage robots to complete patient intake.",
      "In fact, machines are infused with our biases, because the healthcare providers who contribute to the education of these robots consistently rate pain with bias. The chilling reality is that we have seen time and again how race, age, and gender can all affect how your condition is assessed as well as the urgency with which you are treated.",
      "When I was six, my Black father and white adoptive mother moved my family from Togo, where I was born, to Ithaca, New York. It was in New York that I had one of my first experiences navigating the U.S. healthcare system. That experience taught me early that the systems meant to help us are often designed without us in mind.",
    ],
  },
]

// Helper function to get a post by slug
export function getPostBySlug(slug: string): BlogPost | undefined {
  return blogPosts.find((post) => post.slug === slug)
}

// Helper function to get all slugs for static generation
export function getAllPostSlugs(): string[] {
  return blogPosts.map((post) => post.slug)
}

// Helper function to get posts by category
export function getPostsByCategory(category: string): BlogPost[] {
  if (category === "All") return blogPosts
  return blogPosts.filter((post) => post.category === category)
}

// Get all unique categories
export function getAllCategories(): string[] {
  const categories = new Set(blogPosts.map((post) => post.category))
  return ["All", ...Array.from(categories)]
}
